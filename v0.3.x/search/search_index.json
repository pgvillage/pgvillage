{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"about/license/","title":"License","text":"<p>The MIT License (MIT)</p> <p>Copyright (c) 2016 Andrew Rothstein</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"administrators-guide/deployment_and_maintenance/ansible/","title":"Ansible","text":"<p>This document describes how to deploy the PostgreSQL standard building block using Ansible.</p> <p>Before running Ansible, ensure that all prerequisites are correctly configured.</p>"},{"location":"administrators-guide/deployment_and_maintenance/ansible/#1-prerequisites","title":"1. Prerequisites","text":""},{"location":"administrators-guide/deployment_and_maintenance/ansible/#11-ssh-setup","title":"1.1 SSH Setup","text":"<p>Ensure that SSH access is properly configured.</p> <ul> <li>In our predefinied deployments (<code>pgv_azure</code> and <code>pgv_vagrant</code>) this is already taken care of.   For on-prem deployments, make sure that a user with proper permissions and ssh authentication is created.</li> <li>Git clone and Ansible setup of the Ansible code (this work instruction)</li> </ul>"},{"location":"administrators-guide/deployment_and_maintenance/ansible/#2-materials-needed","title":"2. Materials needed","text":"<p>To perform this procedure, you will need:</p> <ul> <li>Access to the management server   (See also the SSH documentation)</li> <li>Access to the Ansible code repository: https://github.com/pgvillage/pgvillage</li> </ul>"},{"location":"administrators-guide/deployment_and_maintenance/ansible/#3-working-instruction","title":"3. Working instruction","text":""},{"location":"administrators-guide/deployment_and_maintenance/ansible/#step-1-clone-the-repository","title":"Step 1: Clone the repository","text":"<p>Create a Git folder in your home directory, navigate into it, and clone the repository:</p> <pre><code>mkdir -p ~/git\ncd ~/git\ngit clone git@github.com:pgvillage/pgvillage.git\n</code></pre>"},{"location":"administrators-guide/deployment_and_maintenance/ansible/#step-2-optional-adjust-the-inventory-configuration","title":"Step 2: (Optional) Adjust the inventory configuration","text":"<p>Optionally adjust the inventory configuration to suit your environment. For detailed steps, refer to: From Server to Running Database</p>"},{"location":"administrators-guide/deployment_and_maintenance/ansible/#step-3-run-the-ansible-playbook","title":"Step 3: Run the Ansible Playbook","text":""},{"location":"administrators-guide/deployment_and_maintenance/ansible/#31-navigate-to-the-ansible-directory","title":"3.1 Navigate to the Ansible directory","text":"<p>Go to the cloned Ansible repository directory:</p> <pre><code>cd ~/git/ansible-postgres\n</code></pre>"},{"location":"administrators-guide/deployment_and_maintenance/ansible/#32-run-everything","title":"3.2 Run everything","text":"<p>Execute all roles for the selected environment:</p> <pre><code>ansible-playbook -i environments/[ENV] functional-all.yml\n</code></pre>"},{"location":"administrators-guide/deployment_and_maintenance/ansible/#33-run-specific-roles-example","title":"3.3 Run specific roles (example)","text":"<p>If you want to run only specific roles (for example, <code>stolon</code> and <code>avchecker</code>):</p> <pre><code>ansible-playbook -i environments/[ENV] functional-all.yml --tags stolon,avchecker\n</code></pre>"},{"location":"administrators-guide/deployment_and_maintenance/ansible/#34-additional-examples","title":"3.4 Additional examples","text":"<p>For other related examples and procedures, refer to the following documentation:</p> <ul> <li>Chainsmith</li> <li>Inventory</li> </ul>"},{"location":"administrators-guide/deployment_and_maintenance/inventory/","title":"Introduction","text":"<p>Once the new servers are available, they can be deployed as new database, backup, and (optionally) routing servers.</p> <p>Dit wordt gedaan middels Ansible. Deze beschrijving kan gebruikt worden om de inventory met de juiste informatie te laden</p> <p>and running Ansible to create a running database cluster.</p>"},{"location":"administrators-guide/deployment_and_maintenance/inventory/#requirements","title":"Requirements","text":"<ul> <li>3 (or more) database servers, 1 backup server (and optionally 2 router servers)</li> <li>Requested through a change request (see from database request to server request for more information).</li> <li>Delivered by SHS</li> <li>Management server with the correct configuration: ssh config, ansible config</li> </ul>"},{"location":"administrators-guide/deployment_and_maintenance/inventory/#instruction-manual","title":"Instruction Manual","text":"<p>1: Controleer dat de opgeleverde servers voldoen aan de aanvragen. Controleer o.a.:</p> <ul> <li>iptables</li> <li>On the database servers, ports 5432, 25432, 2379, and 2380 must be open.</li> <li>On the backup server, port 9091 must be open.</li> <li>On the router servers (if applicable), ports 5432 and 5433 must be open.</li> <li>storage</li> <li>On the database servers, <code>/data/postgres/data</code> and <code>/data/postgres/wal</code> must be available with sufficient space.</li> <li>On the backup server, <code>/data/postgres/backup</code> must be available with sufficient space.</li> <li>CPU and memory</li> <li>Database server: See server request form.</li> <li>Backup server: 1 CPU and 4G is sufficient.</li> <li>Router servers (if applicable): 1 CPU and 4 G is sufficient.</li> </ul> <p>2: Make sure the inventory has been created and filled out correctly.</p> <p>The inventory can (for example) be copied from an existing inventory and possibly even assembled itself.</p> <p>Examples:</p> <ul> <li><code>environments/poc</code> explains how it works in the POC environment: PG14, including router configuration.</li> <li><code>environments/geo_a</code> relates to a solution with PG14 and PostGIS.</li> <li><code>environments/vbe_a</code> pertains to a solution with PostgreSQL 12, router, foreign data wrapper, and pgQuartz jobs.</li> </ul> <p>Let's move on to the following:</p> <pre><code>- postgres version:\n  - environments/[ENV]/group_vars/all/generic.yml:\u00a0postgresql_version\n  - environments/[ENV]/group_vars/all/packages.yml:\u00a0linux_rhsm_poolids\n    - see examples in\u00a0\"environments/vbe_t/group_vars/all/packages.yml\" (PG12) and\u00a0\"environments/geo_a/group_vars/all/packages.yml\" (PG14)\n- router config:\n  - environments/[ENV]/group_vars/all/generic.yml:\u00a0postgresql_vip_fqdn,\u00a0postgresql_vip_ip en\u00a0postgresql_subnet\n  - environments/[ENV]/group_vars/all/generic.yml:\u00a0haproxy_rw_backends en\u00a0haproxy_ro_backends\n- Foreign data wrapper:\n  - environments/[ENV]/group_vars/all/generic.yml: stolon_keeper_extra_env_vars en\u00a0stolon_package_names\n  - environments/[ENV]/group_vars/all/generic.yml: stolon_keeper_extra_env_vars\n- PgQuartz:\n  - environments/[ENV]/group_vars/all/generic.yml: pgquartz_definitions,\u00a0pgquartz_jobs\n- PostgIS:\n  - environments/[ENV]/group_vars/hacluster/packages.yml:\u00a0linux_packages.postgres\n- pg_hba config\n  - environments/[ENV]/group_vars/all/generic.yml: stolon_pg_hba\n    - The first and second line must remain:\n</code></pre> <ul> <li><code>local all all</code> identify</li> <li> <p><code>ident</code></p> </li> <li> <p>hostssl postgres avchecker samenet cert</p> </li> <li>The rest must be in accordance with the database request form (information at <code>Host Based Access</code> table)</li> </ul> <p>For example, to create a new inventory based on <code>geo_a</code>:</p> <ul> <li>Create a new branch and merge request</li> <li>Copy from an existing inventory</li> </ul> <pre><code>NEW*ENV=[ENV]*[OMGEVING]\n</code></pre> <pre><code>git checkout -b feature/$NEW_ENV dev\n</code></pre> <pre><code>rsync -av environments/geo_a environments/$NEW_ENV\n</code></pre> <pre><code>Adjust the following files as needed: `environments/$NEW_ENV/hosts` and `environments/$NEW_ENV/group_vars/all/generic.yml`\n</code></pre> <p>Adjust the environment as needed. At least configure the following files:</p> <pre><code>- environments/[ENV]/hosts\n  - fill in the correct hostnames\n- environments/[ENV]/group_vars/all/generic.yml\n  - pg_hba configuration\n</code></pre> <p>3: create the client certificates according to the work instruction generate new certificates</p> <pre><code>4: Create a new commit, push and make a merge request (create it as a draft MR)\n</code></pre> <pre><code>NEW_ENV=[ENV]_[OMGEVING]\n</code></pre> <pre><code>git add environments/$NEW_ENV\n</code></pre> <pre><code>git commit -m \"New environment $NEW_ENV\"\n</code></pre> <p>git push</p>"},{"location":"administrators-guide/deployment_and_maintenance/inventory/#glab-or-follow-the-link-in-the-output-of-the-git-push-command","title":"glab, or follow the link in the output of the <code>git push</code> command","text":"<p>glab mr create</p> <p>5:\u00a0Execute Ansible, check the output and resolve any issues according to the Ansible documentation</p>"},{"location":"administrators-guide/deployment_and_maintenance/inventory/#check-the-result","title":"Check the result:","text":"<ul> <li>Ensure that Postgres is working and check the PostgreSQL version:</li> </ul> <pre><code>psql --version\n</code></pre> <pre><code>ssh gurus-dbtdb-server3.int.corp.com\n</code></pre> <pre><code>Last login: Thu Oct 2015 10:06 from 10.0.6.100\n</code></pre> <pre><code>[me@gurus-dbtdb-server3~]$ sudo iu postgres\n</code></pre>"},{"location":"administrators-guide/deployment_and_maintenance/inventory/#clusterinfo","title":"ClusterInfo","text":"<pre><code>MasterKeeper: gurus_dbtdb_server2\n</code></pre>"},{"location":"administrators-guide/deployment_and_maintenance/inventory/#keepersdbtree","title":"Keepers/DBtree","text":"<pre><code>gurus_dbtdb_server2 (master)\n</code></pre> <pre><code>\u2502\u2500\u2500 gurus_dbtdb_server3\n</code></pre> <pre><code>\u2514\u2500gurus_dbtdb_server1\n</code></pre> <pre><code>[postgres@gurus-dbtdb-server3~]$ psql service=proxy\n</code></pre> <p>psql(14.5)</p> <pre><code>SSL connection (protocol: TLSv1.3, cipher: TLS_AES_256_GCM_SHA384, bits: 256, compression: off)\n</code></pre> <p>Type \"help\" for help.</p> <pre><code>postgres=#\n\n- Check the status of [avchecker](../../../../../../../../pages/xwiki/Infrastructuur/Team%3A+DBA/Werkinstrukties/Postgres/Bouwsteen/AV+checker/WebHome.html)\n- Create users as per [Extra database en/of user aanmaken](../../../../../../../../pages/xwiki/Infrastructuur/Team%3A+DBA/Werkinstrukties/Postgres/Bouwsteen/Bestaand+cluster+aanpassen/WebHome.html)\n\nIf everything is okay after the rollout, mark the Merge Request as Ready and ensure that the Merge Request gets merged.\n</code></pre>"},{"location":"administrators-guide/deployment_and_maintenance/modify_existing/","title":"Modifying an existing deployment","text":""},{"location":"administrators-guide/deployment_and_maintenance/modify_existing/#introduction","title":"Introduction","text":"<p>Als onderdeel van het aanmaken van een nieuw cluster moet ook database users en databases aangemaakt worden.</p> <p>The ambition is to manage this automatically based on PGFA.</p> <p>Voorlopig doen we dit met de hand.</p>"},{"location":"administrators-guide/deployment_and_maintenance/modify_existing/#dependencies","title":"Dependencies","text":"<ul> <li>Ansible setup according to Ansible documentation</li> <li>A properly stored database request form in teams:</li> <li>Acme-IV-BI-Ops &gt; General &gt; Files &gt; Database Request Forms &gt;</li> <li>A running PostgreSQL cluster. Optionally, you can:</li> <li>request servers according to From database request to server request</li> <li>deploy via [link label] from servers to running database<ul> <li>This procedure is part of that procedure, so it should be good after this.</li> </ul> </li> </ul>"},{"location":"administrators-guide/deployment_and_maintenance/modify_existing/#werkinstructie","title":"Werkinstructie","text":"<p>1: create user and database with <code>psql</code></p> <p>Maak de users aan met de psql tool:</p> <pre><code>me@gurus-dbabh-server1 ~&gt; ssh gurus-pgsdb-server1.int.corp.com\n</code></pre> <pre><code>[me@gurus-pgsdb-server1 ~] $ sudo -iu postgres\n</code></pre>"},{"location":"administrators-guide/deployment_and_maintenance/modify_existing/#cluster-information","title":"Cluster Information","text":"<pre><code>Master Keeper: gurus_pgssdb_l10\n\ngurus_pgsdb_server1 (master)\n\u251c\u2500gurus_pg_s_db_server2\n\u2514\u2500gurus_pg_s_db_server3\n\n[postgres@gurus-pgsdb-server1 ~]$ psql service=master\n\npsql (14.5)\n\nSSL connection (protocol: TLSv1.3, cipher: TLS_AES_256_GCM_SHA384, bits: 256, compression: off)\n\nType \"help\" for help.\n\npostgres=# CREATE USER new_user;\n\nCREATE ROLE\n\ncreate_new_db=# \\password create_new_user\n\nEnter new password for user \"new_user\":\n\nEnter it again:\n\npostgres=# CREATE DATABASE new_db OWNER new_user;\n\nCREATE DATABASE\n\nREVOKE CONNECT ON DATABASE new_db FROM PUBLIC;\n\nREVOKE\n\nnew_db=GRANT CONNECT ON DATABASE new_db TO new_user;\n\nGRANT\n\nnew_db=#\n</code></pre> <p>2: Adjustments to <code>hba.conf</code></p> <p>Execute everything on the gurus-dbabh-server1:</p> <p>First, create a new feature (not for expanding on new database servers, only for adjusting existing clusters):</p> <p>ENV=poc</p> <pre><code>git checkout -b feature/changed*hba*$ENV dev\n</code></pre> <pre><code>Adjust the HBA configuration in `environments/$ENV/group_vars/all/generic.yml`\n</code></pre> <p>Adjust the HBA configuration as needed.</p> <p>Be aware that for traffic via stolon-proxy, an accompanying SELinux rule must also be created.</p> <p>Als de hba config naar behoren is aangepast kan deze worden toegepast middels:</p> <p>ENV=poc</p> <pre><code>exportANSIBLE_VAULT_PASSWORD_FILE=~/git/ansible-postgres/bin/gpgvault\n</code></pre> <pre><code>ansible-playbook -i environments/$ENV functional-all.yml --tags stolon\n</code></pre> <p>Then create a Merge Request (not for expanding on new database servers, only when adjusting existing clusters):</p> <p>ENV=poc</p> <pre><code>git add environments/$ENV\n</code></pre> <pre><code>git commit -m \"HBA adjustments $ENV\"\n</code></pre> <p>git push</p>"},{"location":"administrators-guide/deployment_and_maintenance/modify_existing/#glab-or-follow-the-link-in-the-output-of-the-git-push-command","title":"glab, or follow the link in the output of the <code>git push</code> command","text":"<p>glab mr create</p> <p>Check if everything has been rolled out properly:</p> <pre><code>me@gurus-dbabh-server1~&gt; ssh gurus-pgsdb-server1.int.corp.com\n</code></pre> <pre><code>[me@gurus-pgsdb-server1~] $ sudo -i postgres\n</code></pre> <pre><code>===ClusterInfo===\n</code></pre>"},{"location":"administrators-guide/deployment_and_maintenance/modify_existing/#masterkeeper-gurus_pgssdb_server1","title":"MasterKeeper: gurus_pgssdb_server1","text":"<p>==Keepers/DBtree==</p> <pre><code>gurus_pgsdb_server1 (master)\n</code></pre> <p>\u251c\u2500gurus_pgsdb_server2</p> <p>\u2514\u2500gurus_pgsdb_server3</p> <pre><code>[postgres@gurus-pgsdb-server1~] $ psql service=master\n</code></pre>"},{"location":"administrators-guide/deployment_and_maintenance/modify_existing/#psql-145","title":"<code>psql (14.5)</code>","text":"<pre><code>SSL connection (protocol: TLSv1.3, cipher: TLS_AES_256_GCM_SHA384, bits: 256, compression: off)\n</code></pre> <p>Type \"help\" for help.</p> <pre><code>postgres=# select \\* from pg_hba_file_rules;\n</code></pre> <pre><code>line_number | type | database | user_name | address | netmask | auth_method | options | error\n</code></pre> <p>-------------+---------+---------------+-------------+---------------+-----------------+-------------+--------------------------+-------</p> <pre><code>1| local | postgres | postgres |||| peer |\n</code></pre> <pre><code>2 | local | replication | postgres ||| peer ||\n</code></pre> <pre><code>3 | hostssl | all | postgres | 10.0.5.67 | 255.255.255.255 | cert | clientcert=verify-full |\n</code></pre> <pre><code>4 | hostssl | {replication} | {postgres} | 10.0.5.67 | 255.255.255.255 | cert | {clientcert=verify-full} |\n</code></pre> <pre><code>5 | hostssl | {all} | postgres | 10.0.5.68 | 255.255.255.255 | cert | clientcert=verify-full |\n</code></pre> <pre><code>6|hostssl| {replication}| {postgres} |10.0.5.68|255.255.255.255|cert| {clientcert=verify-full} |\n</code></pre> <pre><code>7|local|{all} |{all}| ||peer||\n</code></pre> <pre><code>8 | hostssl | {postgres} | {avchecker} | samenet | cert | clientcert=verify-full |\n</code></pre> <pre><code>9 | hostssl | all | all | samenet | cert | clientcert=verify-full |\n</code></pre> <p>(9rows)</p> <pre><code># postgres=#\n</code></pre> <p>If everything looks good, then the status of the Merge Request can be changed to Ready.</p> <p>3: nieuwe client certificaten</p> <p>If necessary, these can be created according to the procedure for new client certificates.</p>"},{"location":"administrators-guide/deployment_and_maintenance/patching_procedure/","title":"Introduction","text":"<p>Het SBB is speciaal ontworpen om High Availability te kunnen garanderen.</p> <p>Patching mag hier weinig tot geen impact op hebben.</p> <p>Deze documentatie beschrijft hoe Patching vand eze HA omgeving plaats vindt en welek HA opties hiermee gegarandeerd worden.</p>"},{"location":"administrators-guide/deployment_and_maintenance/patching_procedure/#dependencies","title":"Dependencies","text":"<ul> <li>Satellite:\u00a0https://gurus-satl6-server1.int.corp.com/</li> <li>Here, the various patchsets per environment are maintained</li> <li>The SHS Patch Process</li> <li>In this process, servers are divided into server groups (A, B, C, and D)</li> <li>The server groups are patched as a whole</li> <li>Patching is done entirely automatically</li> <li>The DBA team remains informed about the patching</li> <li>The Demote Script:</li> <li>~postgres/bin/demote.sh (Ansible managed in the stolon role)</li> <li>Is executed before patching is performed</li> <li>Ensures that \"this server is no longer a master\"</li> <li>Only works if everything comes back correctly after patching</li> </ul>"},{"location":"administrators-guide/deployment_and_maintenance/patching_procedure/#facts","title":"Facts","text":"<ul> <li>The starting point is not that there are no issues</li> <li>the starting point is that all issues in A are encountered and resolved</li> <li>the starting point is that at P all issues have been encountered and resolved</li> <li>~postgres/bin/demote.sh</li> <li>is executed by the patching process so that switchover can be carried out quickly</li> <li>This has an impact on running transactions (they are canceled, application may reinitiate them)</li> <li>This has an impact on maintenance jobs</li> <li>After\u00a0~postgres/bin/demote.sh, patching and reboot have almost no more impact</li> <li>The impact is a catch-up when the database server is back from the reboot</li> <li>The impact is also that read-only (RO) queries are terminated if the server reboots (see router).</li> <li>Application clients must</li> <li>use Client Connect Failover, or</li> <li>use a router with a VIP</li> <li>The router uses KeepAliveD and is configured without preferred master</li> <li>the server that was master and reboots causes a failover to the other router</li> <li>per patch round, a maximum of 2 failovers can occur</li> <li>servers are patched separately, so there is always one available<ul> <li>as long as after a patch round of a group an intake takes place</li> </ul> </li> </ul>"},{"location":"administrators-guide/deployment_and_maintenance/point_in_time_restore/","title":"Point in time restore","text":""},{"location":"administrators-guide/deployment_and_maintenance/point_in_time_restore/#important","title":"Important","text":"<ol> <li>In almost all cases, the reason for a point-in-time restore is not due to an error in the PostgreSQL architecture or by the DBA.</li> </ol> <pre><code>Daarom is in bijna alle gevallen Point in time Restore ook geen downtime van de dienst.\n\nTake the time to perform a proper Point-in-Time Restore...\n\n2. In a Shared Cluster setup, it's important that a single database is restored while the rest remain available as usual.\n\nActually, this is not a feature of the standard building block, but it can be executed.\n\nSee chapter _Restore of Some Databases or Tables_ for more information.\n\n## Restore to point in time\n\n[WAL-g](../../../../../../../../../pages/xwiki/Infrastructuur/Team%253A+DBA/Werkinstrukties/Postgres/Bouwsteen/WAL-g/WebHome.html) supports performing a restore to Point in Time, but the procedure in combination with [stolon](../../../../../../../../../pages/xwiki/Infrastructuur/Team%253A+DBA/Werkinstrukties/Postgres/Bouwsteen/Stolon/WebHome.html) (High Availability Cluster Management) is complex.\n\n```markdown\nThat's why it is included in an Ansible playbook, which does the following:\n</code></pre> <ul> <li>Stop the stolon-keeper on all nodes</li> <li>Remove the Postgres data and recreate the folders with the correct permissions</li> <li>Generate the stolon custom_config required to perform a Point In Time Restore using stolon and wal-g</li> <li>Load the custom_config into the etcd config of stolon</li> <li>Start stolon-keeper (one by one per node)</li> <li>Stolon starts on the master and<ul> <li>Finds pitr as the init mode and executes the restore script.</li> <li>The restore script runs wal-g backup-fetch to restore data to the last backup for the point in time</li> <li>Starts Postgres afterwards, which performs recovery up to a specific point in time</li> <li>Uses the restore_command to retrieve WAL-files using wal-g</li> <li>Once Postgres is done with recovery (up to the point in time), PostgreSQL becomes available</li> </ul> </li> <li>PostgreSQL is again available for the application</li> <li>Meanwhile, the standbys start, they clone from the master and become ReadOnly available</li> </ul>"},{"location":"administrators-guide/deployment_and_maintenance/point_in_time_restore/#performance","title":"Performance","text":"<p>Point-in-time restore can be executed from the management server:</p> <p>1: go via SSH to the management server</p> <pre><code>2: Ensure a good Ansible configuration: [Ansible](../../../../../../../../../pages/xwiki/Infrastructuur/Team%3A+DBA/Werkinstrukties/Postgres/Bouwsteen/ansible/WebHome.html)\n</code></pre> <p>3: voer Point in Time restore uit middels Ansible. Een paar voorbeelden:</p> <pre><code>cd ~/git/ansible-postgres\n</code></pre> <pre><code>export ANSIBLE_VAULT_PASSWORD_FILE=$PWD/bin/gpgvault\n</code></pre> <pre><code># Restore to August 30, 2022 at 09:10:11 AM:\n</code></pre> <pre><code>ansible-playbook -i environments/poc/ ./restore.yml -e 'restore_target=\"2022-08-30T09:10:11\"'\n</code></pre> <pre><code># Restore to the label mylabel1:\n</code></pre> <pre><code>ansible-playbook -i environments/poc/ ./restore.yml -e restore_target=\"mylabel1\"\n</code></pre>"},{"location":"administrators-guide/deployment_and_maintenance/point_in_time_restore/#restore-to-transaction-id-50851","title":"Restore to transaction ID 50851","text":"<pre><code>ansible-playbook -i environments/poc/ ./restore.yml -e restore_target=\"50851\"\n</code></pre> <p>For a restore until the last moment, simply do not specify <code>-e restore_target=...</code>!</p> <p>Think about this: The <code>RESTORETARGETINPUT</code> is written (appended) to <code>/etc/default/wal-g</code>. Even if the restore goes well, it will not be removed! Check manually and adjust for starting restore.</p> <p>Also check for <code>backup</code> files in the data directory that are created after a restore on the master and make a backup after the restore!</p>"},{"location":"administrators-guide/deployment_and_maintenance/point_in_time_restore/#markdown","title":"```markdown","text":"<p>Restore some database or table</p> <pre><code>In a Shared Cluster setup, it's important that a single database is restored while the rest remains available.\n\nEigenlijk is dit geen feature van het standaard bouwblok, maar kan dit wel uitgevoerd worden:\n\n- Make a standby available (stop stolon-keeper as root or with adm account and sudo)\n- Optionally free up or expand disk space there\n- Set PGRESTORE to a value other than PGDATA (etc. export `PGRESTORE=`)\n- Run the restore script with a restoration location, restore target, etc.:\n</code></pre> <p>/opt/wal-g/scripts/restore.sh \"/data/postgres/data/restore\" \"2022-08-30 09:10:11\"</p> <ul> <li>Start the instance manually, etc.</li> </ul> <pre><code>```markdown\n/usr/pgsql-12/bin/pg_ctl start -D \"/data/postgres/data/restore\"\n</code></pre> <p>NOTE: This can be set up alongside an existing instance, as it starts on port 5433!!!</p> <ol> <li>Copy the data that needs to be restored to the master instance. For example:</li> </ol>"},{"location":"administrators-guide/deployment_and_maintenance/point_in_time_restore/#-schema","title":"- schema:","text":"<pre><code>pg_dump [database] -n [myschema] | psql service=master\n- Table (first truncate):\n- pg_dump [database] -t \"[myschema].[mytable]\" | psql service=master\n3. Stop the instance, discard the restore data\n</code></pre> <pre><code>/usr/pgsql-12/bin/pg_ctl stop -D \"/data/postgres/data/restore\"\n</code></pre> <pre><code>rm -rf \"/data/postgres/data/restore\"  \n4. Restart Stolon Keeper (as root or with the `adm` account and `sudo`)\n</code></pre>"},{"location":"administrators-guide/deployment_and_maintenance/refresh_certificates/","title":"Introduction","text":"<p>In the SBB PostgreSQL, an mTLS chain is used with server- and client- certificates.</p> <p>The chain is generated using Chainsmith and (re)generated using this procedure.</p>"},{"location":"administrators-guide/deployment_and_maintenance/refresh_certificates/#dependencies","title":"Dependencies","text":"<ul> <li>chainsmith</li> <li>nieuwe uitrol</li> <li>ansible-postgres</li> <li>rollout new certs</li> <li>chainsmith config</li> </ul>"},{"location":"administrators-guide/deployment_and_maintenance/refresh_certificates/#werkinstructies","title":"Werkinstructies","text":"<p>1: Check the database request form and create new client certificates if necessary in the chainsmith configuration:</p> <ul> <li>Adjust ansible/config/chainmaker_[ENV].yml</li> </ul> <p>Make a new merge request if necessary:</p> <p>ENV=poc</p> <pre><code>git checkout dev -b \"feature/chainsmith\\_$(printenv ENV).yml\"\n</code></pre> <pre><code>git add config/chainsmith\\_$ENV.yml\n</code></pre> <pre><code>git commit -m \"New chainsmith config $ENV\"\n</code></pre> <p>git push</p>"},{"location":"administrators-guide/deployment_and_maintenance/refresh_certificates/#use-glab-or-follow-the-link-in-the-output-of-the-git-push-command","title":"Use <code>glab</code>, or follow the link in the output of the <code>git push</code> command.","text":"<p>glab mr create</p> <p>Let op dat de juiste extensions ook enabled zijn.</p> <ul> <li>JDBC requires the following extensions (both client and server):</li> <li>keyUsages:<ul> <li>keyEncipherment</li> <li>dataEncipherment</li> <li>digitalSignature</li> </ul> </li> <li>extendedKeyUsages:<ul> <li>serverAuth</li> </ul> </li> </ul> <pre><code>2: Generate the new certificates.\n</code></pre> <p>There are actually three options:</p> <ol> <li>Restart Chainsmith and replace certificates with downtime</li> <li>Ideal for new environments</li> <li>Easiest, but involves downtime</li> <li>ENV=poc</li> </ol> <pre><code>rm environments/$ENV/group_vars/all/certs{,.vault}.yml\n</code></pre> <pre><code>bin/chainsmith.sh $ENV\n\n- Roll out the new certificates afterwards\n\n2. A procedure where [server and client certificates are replaced with minimal impact](../../../../../../../../../pages/xwiki/Infrastructuur/Team%253A+DBA/Werkinstrukties/Postgres/Bouwsteen/mTLS/Certificaten+vervangen+met+weinig+impact/WebHome.html)\n\n   - Manual work, but little to no downtime\n\n3. [New client certificates](https://wiki.corp.com:443/xwiki/bin/create/Infrastructuur/Team%3A%20DBA/Werkinstrukties/Postgres/Bouwsteen/Onderhoud/Nieuwe%20certificaten%20genereren%20en%20uitrollen/nieuwe%20client%20certificaten/WebHome?parent=Infrastructuur.Team%5C%3A+DBA.Algemene+Restore+Server+voor+DBA-Linux.Postgres.Bouwsteen.Onderhoud.Nieuwe+certificaten+genereren+en%20uitrollen.WebHome) added to the existing bundle\n   - Easy and no downtime, but does not help fix issues like expiry\n</code></pre> <p>Volg een van deze procedures en Postgres en de applicatie draaien met de gewenste certificaten.</p>"},{"location":"administrators-guide/deployment_and_maintenance/replacing_certificates/","title":"Refreshing certificates (2)","text":""},{"location":"administrators-guide/deployment_and_maintenance/replacing_certificates/#introduction","title":"Introduction","text":"<p>Certificates are internally generated using an automation tool called chainsmith.</p> <p>De basis hiervoor is echter om een nieuwe chain te genereren en te vervangen in 1 swing.</p> <p>Dit betekent ook een venster waarin de applicatie het server certificaat van PostgreSQL niet meer accepteert</p> <p>and a window where PostgreSQL no longer accepts the client certificate.</p> <p>Deze documentatie beschrijft een methode waarin binnen een paar handmatige stappen het certificaat wordt vervangen.</p> <p>Best case scenario betekent dit een paar keer een reload van PostgreSQL en een paar keer een reload van de applicatie.</p> <p>In practice, it will likely be a restart a couple of times, but even that is minimal downtime compared to a downtime window of several hours.</p> <pre><code># Dependencies\n\n- Knowledge of [mTLS](../../../../../../../../../pages/xwiki/Infrastructuur/Team%253A+DBA/Werkinstrukties/Postgres/Bouwsteen/mTLS/WebHome.html)\n  - Note that this page is a guide, but reading it does not make one an expert in [mTLS](../../../../../../../../../pages/xwiki/Infrastructuur/Team%253A+DBA/Werkinstrukties/Postgres/Bouwsteen/mTLS/WebHome.html)\n- Knowledge of Postgres and how it functions with mTLS\n- Knowledge of [Ansible](https://docs.ansible.com/), [Ansible inventory](https://docs.ansible.com/ansible/latest/user_guide/intro_inventory.html) and [Ansible-vault](https://docs.ansible.com/ansible/latest/user_guide/vault.html)\n- Knowledge of the application and the associated [PostgreSQL client and how it works with mTLS](../../../../../../../../../pages/xwiki/Infrastructuur/Team%253A+DBA/Werkinstrukties/Postgres/Bouwsteen/Clients/WebHome.html)\n- The option to execute this in a POC environment, a test, and an acceptance environment\n\n# Werkinstructie\n\nThis comes down to this:\n\n- Generate a new chain\n  - According to [Procedure for replacing certificates with minimal downtime](../../../../../../../../../pages/xwiki/Infrastructuur/Team%253A+DBA/Werkinstrukties/Postgres/Bouwsteen/Onderhoud/Nieuwe+certificaten+genereren+en+uitrollen/certificaten+vervangen+met+downtime/WebHome.html)\n- Adjust the configuration so that the root certificates / chains include both old and new certificate bundles\n  - In the Ansible inventory\n  - For the application, also perform a reload (or restart)\n    - From then on, the application will accept both the old and the new server certificate\n    - The client continues to connect with the old certificate\n  - For PostgreSQL and all PostgreSQL components including pgQuartz, pgRoute66, and AVChecker (via Ansible)\n    - From then on, PostgreSQL will accept both the old and new server certificate\n    - PostgreSQL also works from that point onward with the new certificate\n    - All building block tools, including pgQuartz, pgRoute66, and AVChecker, will also log in using the new certificate\n    - Application connections are still accepted via the old client certificate\n- Adjust the application so it logs in with the new client certificate\n  - From then on, the old bundles are no longer necessary\n- Restore the bundles to use only the new certificates\n  - Very important because if a certificate in the chain expires, the (client or server) certificate will no longer be trusted\n  - Adjust in the Ansible inventory\n  - Roll out at PostgreSQL (via Ansible)\n\n## Cancelled\n\n1: Generate a new chain according to [Procedure for replacing certificates with minimal downtime](../../../../../../../../../pages/xwiki/Infrastructuur/Team%253A+DBA/Werkinstrukties/Postgres/Bouwsteen/Onderhoud/Nieuwe+certificaten+genereren+en+uitrollen/certificaten+vervangen+met+downtime/WebHome.html).\n\nSla de nieuwe certificaten op in een Merge Request.\n\n- Create a new merge request if necessary\n\nENV=poc\n\n```markdown\ngit checkout -b \"feature/new_certs_$ENV\" dev\n</code></pre>"},{"location":"administrators-guide/deployment_and_maintenance/replacing_certificates/#glab-or-follow-the-link-in-the-output-of-the-git-push-command","title":"glab, or follow the link in the output of the git push command","text":"<p>glab mr create</p> <ul> <li>ensure that the adjustments are saved in a new commit:</li> </ul> <p>-</p> <p>ENV=poc</p> <pre><code>git add config/chainsmith\\_$ENV.yml environments/$ENV/group_vars/all/certs{,.vault}.yml\n</code></pre> <pre><code>git commit -m \"New chainsmith configuration and certificates for $ENV\"\n</code></pre> <p>git push</p> <p>2: Adjust the configuration so that the root certificates/chains contain both the old and new certificate bundles.</p> <p>The old chain can be found on the existing database servers:</p> <ul> <li><code>~postgres/.postgresql/root.crt</code></li> <li><code>/data/postgres/data/certs/root.crt</code></li> </ul> <p>The easiest way is to prepend these with spaces:</p> <pre><code>[root@gurus-pgsdb-server1 ~]# sed 's/^/    /' ~postgres/.postgresql/root.crt\n</code></pre> <pre><code>-----BEGIN CERTIFICATE-----\n</code></pre> <p>MIIGRTCCBC2gAwIBAgIBATANBgkqhkiG9w0BAQsFADCB1zELMAkGA1UEBhMCTkwx</p> <p>EDAOBgNVBBEMBzM3MjEgTUExEDAOBgNVBAgMB1V0cmVjaHQxEjAQBgNVBAcMCUJp</p> <p>bHRob3ZlbjEiMCAGA1UECQwZQW50b25pZSB2IExlZXV3ZW5ob2VrbG4gOTE9MDsG</p> <p>A1UECgw0Umlqa3NpbnN0aXR1dXQgdm9vciBWb2xrc2dlem9uZGhlaWQgZW4gTWls</p> <p>aWV1IChSSVZNKTEaMBgGA1UECwwRUG9zdGdyZXMgYm91d2Jsb2sxETAPBgNVBAMM</p> <p>...</p> <pre><code>[root@gurus-pgsdb-server1 ~]# sed 's/^/ /' /data/postgres/data/certs/root.crt\n</code></pre> <pre><code>-----BEGIN CERTIFICATE-----\n</code></pre> <p>MIIGRTCCBC2gAwIBAgIBAjANBgkqhkiG9w0BAQsFADCB1zELMAkGA1UEBhMCTkwx</p> <p>EDAOBgNVBBEMBzM3MjEgTUExEDAOBgNVBAgMB1V0cmVjaHQxEjAQBgNVBAcMCUJp</p> <p>bHRob3ZlbjEiMCAGA1UECQwZQW50b25pZSB2IExlZXV3ZW5ob2VrbG4gOTE9MDsG</p> <p>A1UECgw0Umlqa3NpbnN0aXR1dXQgdm9vciBWb2xrc2dlem9uZGhlaWQgZW4gTWls</p> <p>aWV1IChSSVZNKTEaMBgGA1UECwwRUG9zdGdyZXMgYm91d2Jsb2sxETAPBgNVBAMM</p> <p>CHBvc3RncmVzMB4XDTIyMDgxODE2NDgyOVoXDTI5MTExOTE2NDgyOVowgYsxCzAJ</p> <p>...</p> <p>The certificates can simply be added to the current inventory:</p> <p>ENV=poc</p> <pre><code>vim environments/$ENV/group_vars/all/certs.yml\n</code></pre> <pre><code># Add the client certificate to `certs.client.chain` (right before placing the new certificate above it).\n</code></pre> <pre><code># Add the server certificate to certs.server.chain (just before placing the new certificate on top).\n</code></pre> <p>Note: By not including this change in the merge request (MR), we can easily roll it back later.</p>"},{"location":"administrators-guide/deployment_and_maintenance/replacing_certificates/#3-deliver-the-bundle-of-old-and-new-chains-to-the-application-administrators-and-ask-them-to-adjust-the-application-configuration-and-load-the-new-root-certificates","title":"3: Deliver the bundle of old and new chains to the Application Administrators and ask them to adjust the application configuration and load the new root certificates.","text":"<p>Eigenlijk is dit wat bij de vorige stap bij certs.server.chain is geplaatst.</p> <p>4: Reconfigure Postgres and all related tools from the building block:</p> <p>ENV=poc</p> <pre><code>cd ~/git/ansible-postgres\n</code></pre> <pre><code>export ANSIBLE_VAULT_PASSWORD_FILE=~/git/ansible-postgres/bin/gpgvault\n</code></pre> <pre><code>ansible-playbook -i environments/$ENV rollout_new_certs.yml\n</code></pre> <p>5: Deliver the entire bundle (only new <code>root.crt</code>, and the client certificates, configuration readme, etc.) to the application administrator.</p> <p>The procedure De procedure voor 'Antwoord aanvrager can be followed.</p> <p>Request application administrators to register with these new client certificates (configuration adjustment and reload/restart).</p> <pre><code>6: Roll back the changes, push to GitLab, and run Ansible again.\n</code></pre> <p>ENV=poc</p> <p>cd ~/git/ansible-postgres</p> <pre><code>git reset environments/$ENV/group_vars/all/certs{,vault}.yml\n</code></pre> <pre><code>export ANSIBLE_VAULT_PASSWORD_FILE=~/git/ansible-postgres/bin/gpgvault\n</code></pre> <pre><code>ansible-playbook -i environments/$ENV rollout_new_certs.yml --tags stolon\n</code></pre> <p>7: With this, the adjustment has been successfully implemented.</p>"},{"location":"administrators-guide/troubleshooting/connectivity/","title":"Introduction","text":"<p>Om PostgreSQL connectie issues goed te kunnen analyseren is het belangrijk om te begrijpen hoe connecties worden gerouteerd en welke dingen onderweg mis kunnen gaan.</p> <p>Deze documentatie beschrijft de paden die een connectie afleggen en geeft hints welke dingen onderzocht kunnen worden om issues te analyseren en op te lossen.</p>"},{"location":"administrators-guide/troubleshooting/connectivity/#markdown","title":"```markdown","text":"<p>Postgres Read-Write Connections via the Router</p> <pre><code>### How to recognize?\n\nRW connecties via de router worden geiniteerd door de client met de VIP als endpoint en poort 5432 als destination port.\n\nA few examples are:\n\n# A `pg_service` File with the Following Service:\n\n\\[myapp\\]\n\nuser=usr\n</code></pre> <p>password=pwd</p> <pre><code>`host=acme-dvppg1pr-v01p.acme.corp.com`\n</code></pre> <p>port=5432</p> <pre><code>```markdown\nsslmode=verify-full\n</code></pre> <pre><code>dbname=myappdb\n</code></pre> <pre><code># Then a connection with service=myapp\n</code></pre> <pre><code># a libpq connection string like:\n</code></pre> <pre><code>'user=usr password=pwd host=acme-dvppg1pr-v01p.acme.corp.com port=5432 sslmode=verify-full dbname=myappdb'\n</code></pre> <pre><code># a JDBC connection URL as:\n</code></pre> <pre><code>postgresql://usr:pwd@acme-dvppg1pr-v01p.acme.corp.com:5432/myappdb\n</code></pre> <p>RW Router connections can be recognized by:</p> <p>-</p> <ul> <li>The port is 5032.</li> <li>Hostname contains pr-v01.</li> </ul>"},{"location":"administrators-guide/troubleshooting/connectivity/#paths","title":"Paths","text":"<p>The connections follow these paths:</p> <ol> <li>Starts at application level and then (OpenShift?, ) routing, network firewall, etc., all the way to the gateway.</li> <li> <p>To the Virtual IP on port 5432</p> </li> <li> <p>The VirtualIP is linked by KeepaliveD.</p> <ul> <li>Is KeepaliveD OK?</li> <li>Is the VIP attached to one server?</li> <li>Does the network address of the VIP match the network of the interface it's connected to?</li> </ul> </li> <li> <p>Is the firewall active?</p> <ul> <li>What are the firewall rules? <code>sudo iptables -L</code>?</li> <li>Are the app servers included for port 5432?</li> </ul> </li> <li> <p>Arrives at HAProxy</p> </li> <li> <p>Is HAProxy running?</p> </li> <li>What does the haproxy stat command say?<ul> <li>Is there an active PostgresReadWrite-backend? There should be one...</li> <li>Does it match expectations? See HAProxy documentation...</li> </ul> </li> <li>Is PgRoute66 running?</li> <li>Does the logging match expectations? Run with debugging if necessary. See PgRoute66 documentation...</li> <li> <p>Are the PgRoute66 certificates OK? <code>sudo openssl x509 -text -noout -in ~pgroute66/.postgresql/postgresql.crt</code></p> <ul> <li>Check that <code>validity - Not After</code> has not expired</li> <li>Check that <code>X509v3 Key Usage: Digital Signature, Key Encipherment, Data Encipherment</code> is set</li> <li>Ensure the subject ends with <code>CN = pgroute66</code></li> </ul> </li> <li> <p>HAProxy routes to the Postgres primary port 25432</p> </li> <li> <p>Is the firewall active?</p> </li> <li>What are the firewall rules? <code>sudo iptables -L</code></li> <li> <p>Are the router nodes included for port 25432?</p> </li> <li> <p>Port 25432 is stolon-proxy:</p> </li> <li> <p>Is stolon-proxy running on the primary node?</p> </li> <li>What does the avchecker service say<ul> <li>Problem with avchecker@stolon is an issue with Postgres on the primary node</li> <li>Problem with avchecker@proxy is an issue with stolon-proxy</li> <li>Problem with avchecker@routerrw is an issue with the router</li> </ul> </li> <li> <p>Does local connection work via stolon-proxy? <code>sudo -iupostgres bash -c 'psql service=proxy'</code></p> </li> <li> <p>Stolon-proxy routes to the primary Postgres</p> </li> <li>Is there a primary?<ul> <li>Log in on one of the database servers and switch to user postgres. Check the output of stolonctl status which identifies the primary</li> <li>Log in on the primary, become postgres (sudo -iu postgres) and check the status with <code>psql -c 'select pg_is_in_recovery()'</code> (f is expected)</li> </ul> </li> <li>Is the user allowed from the pg_hba config?<ul> <li>Note that the source IP of the traffic are the proxy nodes!!!</li> </ul> </li> <li>What does logging on the primary say? Are there login errors?</li> </ol>"},{"location":"administrators-guide/troubleshooting/connectivity/#_1","title":"```","text":"<p>PostgreSQL RO (Read Only) connections via the router</p> <pre><code>### How to recognize?\n\nRouted connections through the router are initiated by the client with the VIP as the endpoint and port 5433 as the destination port.\n\nA few examples are:\n\n-\n-\n\n```markdown\n# A pg_service file with the following service:\n</code></pre> <p>[myapp]</p> <p>user=usr</p> <p>password=pwd</p> <p><code>host=acme-dvppg1pr-v01p.acme.corp.com</code></p> <pre><code>port=5433\n</code></pre> <pre><code>sslmode=verify-full\n</code></pre> <p>dbname=myappdb</p> <pre><code># Then a connection with service=myapp\n</code></pre> <pre><code># A libpq connection string like:\n</code></pre> <pre><code>'user=usr password=pwd host=acme-dvppg1pr-v01p.acme.corp.com port=5433 sslmode=verify-full dbname=myappdb'\n</code></pre> <p># een jdbc connectie url als:</p> <pre><code>postgres://usr:pwd@acme-dvppg1pr-v01p.acme.corp.com:5433/myappdb\n</code></pre> <p>RO Router connections are recognizable by:</p> <ul> <li>Port is 5433</li> <li>Hostname contains pr-v01</li> </ul>"},{"location":"administrators-guide/troubleshooting/connectivity/#paths_1","title":"Paths","text":"<p>The connections follow these paths:</p> <ol> <li> <p>Begins at the application and then routing, network firewall, etc., up to the gateway.</p> </li> <li> <p>Towards the Virtual IP on port 5433</p> <ul> <li>The VirtualIP is attached by KeepaliveD.</li> <li>Is KeepaliveD OK?</li> <li>Is the VIP attached to one server?</li> <li>Does the network address of the VIP match the network of the interface it's connected to?</li> </ul> </li> <li> <p>Is the firewall active?</p> <ul> <li>What are the firewall rules? <code>sudo iptables -L</code>?</li> <li>Are the application servers included for port 5433?</li> </ul> </li> <li> <p>Arrives at HAProxy</p> </li> <li> <p>Is HAProxy running?</p> </li> <li>What does the haproxy stat command show?<ul> <li>Is there an active PostgresReadOnly-backend? There should be one...</li> <li>Does it match expectations? See HAProxy documentation...</li> </ul> </li> <li>Is PgRoute66 running?</li> <li>Does the logging match expectations? Run with debugging temporarily if necessary. See PgRoute66 documentation...</li> <li> <p>Are the PgRoute66 certificates OK? <code>sudo openssl x509 -text -noout -in ~pgroute66/.postgresql/postgresql.crt</code></p> <ul> <li>Check that <code>validity - Not After</code> has not expired</li> <li>Ensure that <code>X509v3 Key Usage: Digital Signature, Key Encipherment, Data Encipherment</code> is set</li> <li>Verify that the subject ends with <code>CN = pgroute66</code></li> </ul> </li> <li> <p>HAProxy routes to the Postgres standbys (not primary) on port 5432</p> </li> <li>Is the firewall active?<ul> <li>What are the firewall rules? <code>sudo iptables -L</code></li> <li>Are the router nodes included for port 5432?</li> </ul> </li> <li>Is the user allowed from the pg_hba config?<ul> <li>Note that the source IP of the traffic is from the proxy nodes!!!</li> </ul> </li> <li>What does the logging on the standby servers say? Are there login errors? Are there one or more standbys?</li> <li>Log in to one of the database servers as user postgres. Check the output of stolonctl status for which are the standbys</li> <li>Log into the standbys, become postgres (sudo -iu postgres) and check the status with <code>psql -c 'select pg_is_in_recovery()'</code> (it is expected)</li> </ol>"},{"location":"administrators-guide/troubleshooting/connectivity/#markdown_1","title":"```markdown","text":"<p>Stolon Proxy PostgreSQL Read-Write Connections</p> <pre><code>### How to recognize\n\nStolon-proxy read-write connections are initiated by the client with the database servers as the endpoint and port 25432 as the destination port.\n\nA few examples are:\n\n```markdown\n# A `pg_service` file with the following service:\n</code></pre> <p>[myapp]</p> <p>user=usr</p> <p><code>password=pwd</code></p> <pre><code>host=acme-dvppg1db-server1.acme.corp.com, acme-dvppg1db-server2.acme.corp.com, acme-dvppg1db-server3.acme.corp.com\n</code></pre> <p>port=25432</p> <pre><code>sslmode=verify-full\n</code></pre> <p>dbname=myappdb</p>"},{"location":"administrators-guide/troubleshooting/connectivity/#and-then-a-connection-with-servicemyapp","title":"and then a connection with service=myapp","text":"<pre><code># A libpq connection string like:\n</code></pre> <pre><code>'user=usr password=pwd host=acme-dvppg1db-server1.acme.corp.com,acme-dvppg1db-server2.acme.corp.com,acme-dvppg1db-server3.acme.corp.com port=25432 sslmode=verify-full dbname=myappdb'\n</code></pre> <p># een jdbc connectie url als:</p> <pre><code>postgres://usr:pwd@acme-dvppg1db-server1.acme.corp.com,acme-dvppg1db-server2.acme.corp.com,acme-dvppg1db-server3.acme.corp.com:25432/myappdb\n</code></pre> <p>RW Router connections are recognizable by:</p> <ul> <li>Port is 25432</li> <li>Hostname contains <code>db-l0</code></li> </ul>"},{"location":"administrators-guide/troubleshooting/connectivity/#paths_2","title":"Paths","text":"<p>The connections follow the following paths:</p> <ol> <li>Starts with the application, followed by (OpenShift?, ) routing, network firewall, etc., up to the gateway.</li> <li>To the Database server on port 25432</li> <li>Is the firewall active?</li> <li>What are the firewall rules? `sudo iptables -L`?</li> <li>Are the app servers included for port 25432?</li> <li>Port 25432 is stolon-proxy:</li> <li>Is stolon-proxy running?</li> <li>What does the avchecker service say<ul> <li>Issue with avchecker@stolon\u00a0is an issue with Postgres on the primary node</li> <li>Issue with avchecker@proxy is an issue with stolon-proxy</li> </ul> </li> <li>Does local connection work via stolon-proxy? `sudo -iupostgres bash -c 'psql service=proxy'`</li> <li>Stolon-proxy routes to the primary postgres</li> <li>Is there a primary?<ul> <li>Log into one of the database servers as user postgres. Check the output of <code>stolonctl status</code> which shows the primary.</li> <li>Log into the\u00a0primary, becomes postgres (sudo -iu postgres) and check the status with `psql -c 'select pg_is_in_recovery()'` (f is expected)</li> </ul> </li> <li>Is the user allowed from the pg_hba config?<ul> <li>Note that the source IP of the traffic are the proxy nodes!!!</li> </ul> </li> <li>What does the logging on the primary say? Are there login errors?</li> </ol>"},{"location":"administrators-guide/troubleshooting/connectivity/#direct-postgresql-read-write-connections","title":"Direct PostgreSQL Read-Write Connections","text":""},{"location":"administrators-guide/troubleshooting/connectivity/#how-to-recognize","title":"How to recognize","text":"<p>Directe RW connecties worden geiniteerd door de client met de DB servers als endpoint en poort 5432 als destination port.</p> <p>A few examples are:</p> <pre><code># A `pg_service` file with the following service:\n</code></pre> <p>[myapp]</p> <p>user=usr</p> <pre><code>password=pwd\n</code></pre> <pre><code>host=acme-dvppg1db-server1.acme.corp.com, acme-dvppg1db-server2.acme.corp.com, acme-dvppg1db-server3.acme.corp.com\n</code></pre> <p>port=5432</p> <pre><code>sslmode=verify-full\n</code></pre> <p>dbname=myappdb</p> <p>target_session_attrs=read-write</p> <pre><code># and then a connection with service=myapp\n</code></pre> <pre><code># A libpq connection string like:\n</code></pre> <pre><code>'user=usr password=pwd host=acme-dvppg1db-server1.acme.corp.com,acme-dvppg1db-server2.acme.corp.com,acme-dvppg1db-server3.acme.corp.com port=5432 sslmode=verify-full dbname=myappdb target_session_attrs=read-write'\n</code></pre> <p># een jdbc connectie url als:</p> <pre><code>postgres://usr:pwd@acme-dvppg1db-server1.acme.corp.com,acme-dvppg1db-server2.acme.corp.com,acme-dvppg1db-server3.acme.corp.com:5432/myappdb?targetServerType=master\n</code></pre> <p>Directe RW connections can be recognized by:</p> <ul> <li>Port is 5432</li> <li>LibPQ: <code>target_session_attrs</code> = read-write (of primary)</li> <li>JDBC: <code>targetServerType</code> = primary (of master, preferPrimary)</li> <li>Hostname contains db-l0</li> </ul>"},{"location":"administrators-guide/troubleshooting/connectivity/#paths_3","title":"Paths","text":"<p>The connections follow these paths:</p> <ol> <li> <p>Begins with the application and then (OpenShift?, ) routing, network firewall, etc., up to the gateway</p> </li> <li> <p>Is OpenShift routing correctly configured?</p> </li> <li>Does the traffic indeed come from the intended IP address?</li> <li> <p>Is the firewall open for traffic from the AppServer IP to the database nodes?</p> </li> <li> <p>To the Database server on port 5432</p> </li> <li> <p>Is the firewall active?</p> </li> <li>What are the firewall rules? <code>sudo iptables -L</code></li> <li> <p>Are the appserver IPs included for port 5432</p> </li> <li> <p>On port 5432, PostgreSQL is running</p> </li> <li>Is there a primary?<ul> <li>Log in to one of the database servers as user postgres. Check the output of stolonctl status to determine which is the primary.</li> <li>Log in to the primary as postgres (sudo -iu postgres) and check the status with <code>psql -c 'select pg_is_in_recovery()'</code> (f is expected)</li> </ul> </li> <li>Is the user allowed from the pg_hba config?<ul> <li>Note that the source IPs of the traffic are the app servers!!!</li> </ul> </li> <li>What does the logging on the primary say? Are there login errors?</li> </ol>"},{"location":"administrators-guide/troubleshooting/connectivity/#direct-postgresql-connections","title":"Direct PostgreSQL Connections","text":"<p>RO Connectors</p>"},{"location":"administrators-guide/troubleshooting/connectivity/#how-to-recognize_1","title":"How to recognize","text":"<p>Direct RO connections are established by the client with the database hosts as endpoints and port 5432 as the destination port.</p> <p>A few examples are:</p> <pre><code># A `pg_service` file with the following service:\n</code></pre> <pre><code>[myapp]\n</code></pre> <p>user=usr</p> <p>password=pwd</p> <pre><code>host=acme-dvppg1db-server1.acme.corp.com, acme-dvppg1db-server2.acme.corp.com, acme-dvppg1db-server3.acme.corp.com, acme-dvppg1db-server4.acme.corp.com\n</code></pre> <pre><code>port=5432\n</code></pre> <pre><code>sslmode=verify-full\n</code></pre> <pre><code>dbname=myappdb\n</code></pre>"},{"location":"administrators-guide/troubleshooting/connectivity/#with-the-v14-driver","title":"with the v14+ driver","text":"<pre><code>target_session_attrs=read-only # or standby or prefer-standby\n</code></pre>"},{"location":"administrators-guide/troubleshooting/connectivity/#and-then-a-connection-with-servicemyapp_1","title":"and then a connection with service=myapp","text":"<p># a libpq connection string like:</p> <pre><code>'user=usr password=pwd host=acme-dvppg1db-server1.acme.corp.com,acme-dvppg1db-server2.acme.corp.com,acme-dvppg1db-server3.acme.corp.com,acme-dvppg1db-server4.acme.corp.com port=5432 sslmode=verify-full dbname=myappdb target_session_attrs=read-only'\n</code></pre> <pre><code># a JDBC connection URL as:\n</code></pre> <pre><code>postgres://usr:pwd@acme-dvppg1db-server1.acme.corp.com,acme-dvppg1db-server2.acme.corp.com,acme-dvppg1db-server3.acme.corp.com,acme-dvppg1db-server4.acme.corp.com:5432/myappdb?targetServerType=secondary\n</code></pre> <p>RO Router connections can be recognized by:</p> <ul> <li>port is 5432</li> <li>hostname contains db-l0</li> <li>libpq: <code>target_session_attrs=read-only</code> (or <code>standby</code>, <code>prefer-standby</code>)</li> <li>JDBC: <code>targetServerType=secondary</code> (or <code>slave</code>, <code>preferSlave</code>, <code>preferSecondary</code>)</li> </ul>"},{"location":"administrators-guide/troubleshooting/connectivity/#paths_4","title":"Paths","text":"<p>The connections follow the following paths:</p> <pre><code>1. Start at the application level and then proceed to routing (OpenShift?), network firewall, etc., until reaching the gateway.\n2. To the Database hostname on port 5432\n   - Is the firewall active?\n   - What are the firewall rules? `sudo iptables -L`\n   - Are the app servers included for port 5432?\n   - Is the user allowed from the pg_hba configuration?\n     - Note that the source IP of the traffic is the app server IP!!!\n   - What do the logs on the standby servers say? Are there login errors? Are there one or more standbys?\n   - Log in to one of the database servers as user postgres. Check the output of `stolonctl status` which shows the standbys.\n   - Log into the standby's as postgres (sudo -iu postgres) and check the status with `psql -c 'select pg_is_in_recovery()'` (it is expected).\n</code></pre>"},{"location":"administrators-guide/troubleshooting/openssl/","title":"Introduction","text":"<p>Het openssl linux commando kan gebruikt worden voor alle uitvoering van taken mbt certificatane, waaronder:</p> <ul> <li>Generate new private keys, certificate signing requests, certificates, etc. (chainsmith uses openssl)</li> <li>Query information about certificates, including lifetime/expiry, subject/CommonName, x509 extensions, etc.</li> <li>Verification of the combination of a certificate and private key</li> <li>Verification of a certificate chain</li> <li>Conversion of private keys</li> </ul> <p>This documentation describes all OpenSSL commands, what they can be used for, and how certain things can be done.</p>"},{"location":"administrators-guide/troubleshooting/openssl/#commandos","title":"Commandos'","text":"<p># Om te controleren of een private key en een cert bij elkaar horen kunnen de volgende md5 hashes vergeleken worden:</p> <p>openssl rsa -modulus -noout -in \"/data/postgres/data/certs/server.key\" | openssl md5</p> <pre><code>openssl x509 -modulus -noout -in \"/data/postgres/data/certs/server.crt\" | openssl md5\n</code></pre> <pre><code># To read the certificate from a .crt file:\n</code></pre> <p>openssl x509 -text -noout -in /data/postgres/data/certs/server.crt</p> <p># To request a certificate from a web server:</p> <pre><code>openssl s_client -showcerts -servername acme-vbepr-v11a.acme.corp.com -connect acme-vbepr-v11a.acme.corp.com:443 &lt; /dev/null\n</code></pre> <p># To request a certificate from a PostgreSQL server:</p> <pre><code>Open a connection to initiate TLS with the PostgreSQL server on `acme-dvppg1db-server1.acme.corp.com` at port `5432`, and display the certificates using OpenSSL.\n</code></pre> <pre><code># To view the certificate chain that Postgres provides:\n</code></pre> <pre><code>openssl crl2pkcs7 -nocrl -certfile /data/postgres/data/certs/server.crt | openssl pkcs7 -print_certs\n</code></pre> <p># Om te controleren of een certifcaat/chain vertrouwd wordt door een \u00a0ander certificaat</p> <p>openssl verify -CAfile ~postgres/.postgresql/root.crt /data/postgres/data/certs/server.crt</p> <pre><code># To check if a certificate is trusted by an intermediate and root (both separately, not in PG SBB)\n</code></pre> <pre><code>openssl verify -CAfile ~/postgres/.postgresql/root.crt -untrusted ~/postgres/.postgresql/intermediate.crt /data/postgres/data/certs/server.crt\n</code></pre>"},{"location":"administrators-guide/troubleshooting/openssl/#troubleshooting","title":"Troubleshooting","text":""},{"location":"administrators-guide/troubleshooting/openssl/#certificate-expired","title":"Certificate expired","text":"<p>Since work is being done with a single mutual TLS (mTLS) chain where all client and server certificates have the same expiry date, the expiry can be checked on one certificate to validate the entire chain.</p> <p>For querying expiration, the following can be executed:</p> <p>[postgres@acme-dvppg1db-server2 ~]$opensslx509-text-noout-in/data/postgres/data/certs/server.crt|grep-A2Validity</p> <p>Validity</p> <pre><code>NotBefore: Oct 10 04:48:08 2022 GMT\n</code></pre> <pre><code>NotAfter: Oct 10 04:48:08 2023 GMT\n</code></pre> <pre><code>In this example, the certificates expire on October 11, 2023 (4:48 GMT is 6:48 CEST)...\n</code></pre> <pre><code>Om te controleren of een certificaat nog geldig is, kan ook het volgende commando worden gebruikt:\n\n```markdown\n[me@acme-dvppg1db-server1 ~]$ sudo openssl x509 -checkend $(60 * 60 * 24 * 7) -noout -in ~postgres/.postgresql/postgresql.crt\n</code></pre> <p>Certificate will not expire</p> <p>Dit commando kijkt naar expiry in de komende week (3600sec. x 24 uur x 7 dagen)...</p> <p>If the certificates have expired, a new chain must be created and distributed through this procedure: Generate and Roll Out New Certificates</p>"},{"location":"administrators-guide/troubleshooting/openssl/#certificate-is-not-accepted","title":"Certificate is not accepted","text":"<p>To be able to accept connections, the software must trust the certificate, which works through the chain of trust:</p> <ul> <li>The certificate must be trusted by the intermediate certificate</li> <li>The intermediate certificate must be trusted by the root certificate</li> <li>There can be multiple intermediates applied, but for the PostgreSQL building block it is not applicable.</li> <li>The root certificate must be trusted by the software</li> </ul> <p>2 examples:</p> <ul> <li>To establish an SSL connection to PostgreSQL, the client must be able to accept the server certificate.</li> <li>Postgres uses a server certificate for this purpose, which identifies itself: <code>/data/postgres/data/certs/server.crt</code></li> <li>The client (for example, <code>psql</code>) has the chain to validate the server certificate: <code>~postgres/.postgresql/root.crt</code></li> </ul> <p>Note: Actually, the intermediate should be associated with the server certificate and not with the root certificate.</p> <ul> <li>To accept a client connection:</li> <li>The client identifies itself with a certificate: <code>~postgres/.postgresql/postgresql.crt</code></li> <li>This is validated by PostgreSQL using a chain: <code>/data/postgres/data/certs/root.crt</code></li> </ul> <p>The chain can be validated as follows:</p>"},{"location":"administrators-guide/troubleshooting/openssl/#verifierenvanhetservercertificaat","title":"Verifierenvanhetservercertificaat:","text":"<pre><code>[postgres@acme-dvppg1db-server2 ~]$\n</code></pre> <p><code>openssl verify -CAfile ~/postgres/.postgresql/root.crt data/postgres/data/certs/server.crt</code></p> <pre><code>/data/postgres/data/certs/server.crt: OK\n</code></pre>"},{"location":"administrators-guide/troubleshooting/openssl/#verifierenvanhetclientcertificaat","title":"Verifierenvanhetclientcertificaat:","text":"<pre><code>[postgres@acme-dvppg1db-server2 ~] $ openssl verify -CAfile /data/postgres/data/certs/root.crt ~/.postgresql/postgresql.crt\n</code></pre> <p><code>/var/lib/pgsql/.postgresql/postgresql.crt</code>: OK</p> <p>Om andere certificaten te valideren moeten de certificaten dus wel bij elkaar gebracht worden.</p> <p>Copy anything if necessary into the <code>gurus-dbabh-server1</code> in a temporary folder.</p> <p>P.s. certificaten zijn publieke data en niet geheim.</p> <p>Ze kopieren naar tijdelijke folders is dus ook geen security issue.</p>"},{"location":"administrators-guide/troubleshooting/openssl/#markdown","title":"```markdown","text":"<p>subject and CommonName</p> <pre><code>Ieder certificaat heeft een subject en de Common Name is onderdeel van dat subject.\n\nEspecially this Common Name is important because it must match what is attempting to authenticate:\n\n- for server certificates, the Fully Qualified Domain Name (FQDN) of the server\n- for client certificates, the name of the PostgreSQL user\n\nThe subject (and the Common Name) can be easily verified using an `openssl` command:\n\n```bash\nopenssl x509 -in certificate.crt -noout -subject\n</code></pre> <pre><code># Example Server Certificate\n</code></pre> <pre><code>Subject: C=NL, ST=Utrecht, L=Blaricum, O=Nibble IT, OU=PgVillage, CN=localhost\n</code></pre> <pre><code>Subject: C=NL, postalCode=1261 WZ, ST=Utrecht, L=Blaricum, street=Binnendelta 1-u 2, O=Nibble IT, OU=PgVillage, CN=server1.nibble-it.local\n</code></pre> <p># Example Client Certificate</p> <pre><code>Subject: CN=pgfga, O=Nibble-IT, OU=Chainmsith, L=Blaricum, ST=Utrecht, C=NL\n</code></pre> <pre><code>Subject: C=NL, postalCode=1261 WZ, ST=Utrecht, L=Blaricum, street=Binnendelta 1-u 2, O=Nibble-IT, OU=PgVillage, CN=pgfga\n</code></pre> <p>In the example, it can be seen that:</p> <ul> <li>the server certificate with Common Name\u00a0(CN) acme-dvppg1db-server2.acme.corp.com is accepted.</li> <li>The certificate will therefore be accepted when clients connect to this host.</li> <li>the client certificate with Common Name (CN) postgres</li> <li>This certificate will therefore be accepted when the client attempts to log in as the postgres user.</li> </ul>"},{"location":"administrators-guide/troubleshooting/openssl/#x509-extensions-en-san","title":"x509 extensions en SAN","text":"<p>x509 is een certificaten standaard en deze heeft Extensions gedefinieerd.</p> <p>There are 2 important extensions:</p>"},{"location":"administrators-guide/troubleshooting/openssl/#key-usage","title":"Key Usage","text":"<pre><code>JDBC sets very high requirements on client certificates, particularly that the following extensions are enabled:\n</code></pre> <ul> <li>Digital Signature</li> <li>Key Encipherment</li> <li>Data Encryption</li> </ul> <p>Chainsmith is zo geconfigureerd dat hij deze extensies ook enabled.</p> <p>To verify this, the following can be done:</p> <pre><code>[postgres@acme-dvppg1db-server2 ~]$ openssl x509 -text -noout -in data/postgres/data/certs/server.crt | grep -A1 'X509v3 Key Usage:'\n</code></pre> <p>Note: The command is already in English, so no translation was necessary.</p> <p>X509v3KeyUsage:</p> <p>Digital Signature, Key Encipherment, Data Encipherment</p>"},{"location":"administrators-guide/troubleshooting/openssl/#subject-alternative-name","title":"Subject Alternative Name","text":"<p>Since TCP proxies (such as stolon-proxy and HAProxy) are also used in the PostgreSQL architecture, it is possible that a client connects to an FQDN different from that of the server they are actually connecting to.</p> <p>For example, he connects to the VIP (acme-dvppg1 pr-v 01p.acme.corp.com) and accesses the primary database server, such as\u00a0acme-dvppg1 pr-v 02p.acme.corp.com, via HAProxy and stolon-proxy.</p> <p>X.509 has an additional extension called Subject Alternative Names (SAN), which allows for configuring extra hostnames.</p> <p>These can be requested via:</p> <pre><code>[postgres@acme-dvppg1db-server2 ~]$ openssl x509 -text -noout -in /data/postgres/data/certs/server.crt | grep -A1 'X509v3 Subject Alternative Name:'\n</code></pre> <p>Note: The translation task does not apply to shell commands or file paths.</p> <p>X509v3 Subject Alternative Name:</p> <p>DNS: acme-dvppg1db-server2.acme.corp.com, IP Address: 10.0.4.43 DNS: acme-dvppg1pr-v01p.acme.corp.com, IP Address: 10.0.4.28 DNS: acme-dvppg1pr-server1.acme.corp.com, IP Address: 10.0.4.26 DNS: acme-dvppg1pr-server2.acme.corp.com, IP Address: 10.0.4.*27 DNS: acme-dvppg1db-server1.acme.corp.com, IP Address: 10.0.4.42 DNS: acme-dvppg1db-server3.acme.corp.com, IP Address: 10.0.4.44 DNS: acme-dvppg1db-server4.acme.corp.com, IP Address: 10.0.4.45</p> <p>Note: In addition to DNS entries, this SAN also has IP entries, but it seems the PostgreSQL client does not handle them well.</p>"},{"location":"administrators-guide/troubleshooting/openssl/#conversie-private-keys","title":"Conversie Private Keys","text":"<p>For JDBC, a different format (PKCS12 or PKCS8 DER) must be used.</p> <p>Voor DBeaver is specifiek PKCS8 DER zonder wachtwoord nodig.</p> <p>These can be generated with the following commands:</p>"},{"location":"administrators-guide/troubleshooting/openssl/#pkcs8-pem-format","title":"PKCS#8 PEM Format","text":"<pre><code>OpenSSL PKCS#8 -topk8 -inform PEM -outform PEM -in cims_rw.key -out cims_rw.pk8.pem -nocrypt\n</code></pre>"},{"location":"administrators-guide/troubleshooting/openssl/#pkcs8-der-format-suitable-for-jdbc-including-dbeaver","title":"PKCS8 DER Format (Suitable for JDBC including DBeaver)","text":"<pre><code>openssl pkcs8 -topk8 -inform PEM -outform DER -in cims_rw.key -out cims_rw.pk8 -nocrypt\n</code></pre>"},{"location":"administrators-guide/troubleshooting/openssl/#pkcs12-format-also-suitable-for-jdbc-always-with-password","title":"PKCS12 Format (Also Suitable for JDBC, Always with Password)","text":"<pre><code>openssl pkcs12 -export -nocerts -inkey cims_rw.key -out cims_rw.p12\n</code></pre> <p>By the way, a password must sometimes be set for the keys as well:</p>"},{"location":"administrators-guide/troubleshooting/openssl/#pkcs8-pem-format_1","title":"PKCS#8 PEM Format","text":"<pre><code>openssl pkcs8 -topk8 -inform PEM -outform PEM -in cims_rw.key -out cims_rw.pk8.pem\n</code></pre> <pre><code># PKCS8 DER Format (Suitable for JDBC Including DBeaver)\n</code></pre> <pre><code>openssl pkcs8 -topk8 -inform PEM -outform DER -in cims_rw.key -out cims_rw.pk8\n</code></pre> <pre><code># PKCS12 Format (Suitable for JDBC, Always with Password So Same Command)\n</code></pre> <pre><code>openssl pkcs12 -export -nokeys -in cims_rw.pem -out cims_rw.p12\n</code></pre> <p>Chainsmith generates automatically the standard PEM and PKCS8 format keys.</p> <p>These can be found in the temporary folder (or the GPG archive).</p> <p>Example for client certificates for the Postgres user:</p> <ul> <li><code>./tls/int_client/private/postgres.key.pem</code></li> </ul> <p>PEM format</p> <ul> <li><code>./tls/int_client/private/postgres.key.pk8</code></li> </ul> <p>Note: The file path appears to be in English.</p> <p>PKCS#8 format (ASCII)</p> <ul> <li><code>./tls/int_client/private/postgres.key.der</code></li> </ul> <p>PK8 format (DATA)</p>"},{"location":"administrators-guide/troubleshooting/quick_fix/","title":"On-Call Troubleshooting Guide","text":"<p>This page helps you during on-call duty to quickly analyze issues and determine the correct resolution path.</p> <p>Start by identifying the type of problem you are dealing with, then follow the referenced documentation to analyze and resolve it correctly.</p>"},{"location":"administrators-guide/troubleshooting/quick_fix/#application-does-not-have-access-to-postgres","title":"Application does not have access to Postgres","text":"<p>An application requires three key components to successfully access PostgreSQL:</p> <ol> <li>An available PostgreSQL instance</li> <li>Network connectivity</li> <li>A valid configuration</li> </ol> <p>Therefore, the first step in troubleshooting is to identify which of these areas is causing the issue.</p> <ol> <li> <p>Check if Postgres itself is available:</p> </li> <li> <p>Use the checks described in the avchecker documentation.</p> </li> <li> <p>Resolve all issues so that avchecker reports again that Postgres is available.</p> </li> <li> <p>Check if Postgres is available for the application:</p> </li> <li>Network problems are outside the scope of the DBA.</li> </ol> <p>In principle, these kinds of issues are always resolved by network management, or Container Hosting (CHP).</p> <p>Conduct the direction yourself, stay engaged in the process and provide clear information on what works (availability within the Postgres architecture) and what does not work (connectivity of the application to the VIP or to Postgres).</p> <ul> <li> <p>For more information, see the documentation on Connections and Connection Paths</p> </li> <li> <p>Check if the client is correctly configured:</p> </li> </ul> <p>Note</p> <p>Issues from incorrect configuration result  from a change and are actually not part of service availability work!!!</p> <p>Ensure that the client configuration includes:</p> <ul> <li>Host: VIP, or a list of PostgreSQL hosts (comma-separated)</li> <li>Port:</li> <li>5432 (RW on VIP)</li> <li>5433 (RO on VIP)</li> <li>25432 (via stolon-proxy)</li> <li>5432 (direct connection)</li> <li>Username and database name</li> <li>Authentication: client certificates (preferred) or password</li> <li>Session targeting: <code>target_session_attrs</code> (libpq) or <code>targetServerType</code> (JDBC)</li> <li>SSL mode: <code>sslmode=verify-full</code></li> </ul> <p>Additionally:</p> <ul> <li>Verify the PostgreSQL pg_hba.conf configuration.</li> <li>Review application logs with the app administrator.</li> <li>Check for PostgreSQL log errors.</li> <li>For more information, see the documentation on client configuration and about mTLS.</li> </ul>"},{"location":"administrators-guide/troubleshooting/quick_fix/#recovery-emergency-restore","title":"Recovery / Emergency Restore","text":"<p>It may happen that an application administrator requests a point-in-time restore to be performed, for example because too much data has been deleted or to roll back database changes from an application update.</p> <p>It is also possible that due to a disaster scenario all replica instances are no longer available and can only be restored using a Restore (latest point in time).</p> <p>In both situations, this can be resolved by referring to the Point in Time Restore documentation.</p> <p>Note</p> <p>In almost all cases, the reason for a point-in-time restore is not due to an error in the Postgres architecture or by the DBA.</p> <p>Therefore, in almost all cases, a point-in-time restore also does not result in downtime of the service. Take the time to perform a proper point-in-time restore...</p>"},{"location":"administrators-guide/troubleshooting/verify/","title":"Verifying a PgVillage deployment","text":""},{"location":"administrators-guide/troubleshooting/verify/#belongs-to-component","title":"Belongs to component","text":"<p>Bouwsteen Postgres</p>"},{"location":"administrators-guide/troubleshooting/verify/#introduction","title":"Introduction","text":"<p>Bouwsteen Postgres bevat volgende componenten</p> <p>- PostgreSQL</p> <p>- Stolon</p> <p>- Etcd</p> <ul> <li>wal-g</li> </ul>"},{"location":"administrators-guide/troubleshooting/verify/#requirements-and-dependencies","title":"# Requirements and Dependencies","text":"<p>Postgres:</p> <ol> <li><code>sudo su - postgres</code></li> <li><code>psql</code></li> <li><code>create database pgbench;</code></li> <li><code>\\q</code></li> <li><code>/usr/pgsql-12/bin/pgbench -i -s10000 pgbench</code> # filling</li> <li>Test: <code>/usr/pgsql-12/bin/pgbench -c 10 -l -j 4 -P 120 -T 600 pgbench</code></li> </ol> <p>POC result:</p> <p>starting vacuum...end.</p> <pre><code>progress: 120.0 s, 210.3 tps, lat 47.515 ms stddev 29.338\n</code></pre> <pre><code>progress: 240.0 s, 275.6 tps, lat 36.283 ms stddev 21.895\n</code></pre> <pre><code>progress: 360.0 s, 415.2 tps, lat 24.077 ms stddev 49.606\n</code></pre> <p>progress: 480.0 s, 497.7 tps, lat 20.087 ms stddev 18.762</p> <pre><code>\n</code></pre> <p>progress: 600.0 s, 522.0 tps, lat 19.151 ms stddev 16.870</p> <pre><code>```markdown\nTransaction Type: &lt;builtin: TPC-B (sort of)&gt;\n</code></pre> <pre><code>Scaling factor: 10000\n</code></pre> <pre><code>query mode: simple\n</code></pre> <p>number of clients: 10</p> <p>number of threads: 4</p> <pre><code>\n</code></pre> <p>duration: 600 s</p> <pre><code>number of transactions actually processed: 230507\n\n```markdown\naverage latency = 26.023 ms\n</code></pre> <pre><code>latency stddev = 30.854 ms\n</code></pre> <pre><code>tps = 384.125073 (inclusief verbindingsinstellingen)\n</code></pre> <pre><code>tps = 384.128736 (excluding connections establishing)\n</code></pre> <p>Is this good?</p> <p>ETCD:</p> <ol> <li>as postgres: etcdctl check performance</li> <li>can be run on one of the three nodes.</li> </ol> <p>STOLON:</p> <p>on the master: <code>/home/postgres/bin/demote.sh</code></p> <p>on standby: <code>/home/postgres/bin/reinstate.sh</code></p> <p>On a standby or master: reboot or <code>kill -9</code> stolon-keeper.</p> <p>as PostgreSQL user: <code>'stolonctl status'</code></p> <p>== Active Sentinels ==</p> <pre><code>ID \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0LEADER\n</code></pre> <pre><code>81cfd599 false\n</code></pre> <pre><code>d4c10d79 true\n</code></pre> <p>f71041f5 \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0false</p> <pre><code>=== Active Proxies ===\n</code></pre> <p>ID</p> <p>6b72f506</p> <p>b9e1cb00</p> <p>cde31aea</p> <p>=== Keepers ===</p> <pre><code>UID \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0HEALTHY PG LISTEN ADDRESS \u00a0 \u00a0 \u00a0PG HEALTHY \u00a0 \u00a0 \u00a0PG WANTED\nGENERATION \u00a0 \u00a0 \u00a0PG CURRENT GENERATION\n</code></pre> <pre><code>gurus_pgsdb_server1 true 10.0.5.66:5432 true 2 2\n</code></pre> <pre><code>```markdown\ngurus_pgsql_server2 true 10.0.5.67:5432 true 5 5\n</code></pre> <pre><code>gurus_pgsdb_server3 true 10.0.5.68:5432 true 2 2\n</code></pre> <p>=== Cluster Information ===</p> <pre><code>Master Keeper: gurus_pgsdb_server2\n</code></pre> <p>== Keepers/Database Tree ==</p> <p><code>gurus_pgsdb_server2 (master)</code></p> <pre><code>\u251c\u2500gurus_pgsgdb_server3\n</code></pre> <pre><code>- gurus_pgsdb_server1\n</code></pre> <pre><code>Run 24/5/2022\n</code></pre> <p>[postgres@gurus-pgsdb-server2 ~]$ /usr/pgsql-12/bin/pgbench -c 10 -l -j 4 -P 120 -T 600 pgbench</p> <p>starting vacuum...end.</p> <pre><code>progress: 120.0 s, 365.6 tps, lat 27.336 ms stddev 15.355\n</code></pre> <pre><code>progress: 240.0 s, 361.2 tps, lat 27.673 ms stddev 16.090\n</code></pre> <pre><code>progress: 360.0 s, 289.1 tps, lat 34.586 ms stddev 40.564\n</code></pre> <pre><code>progress: 480.0 s, 343.4 tps, lat 29.108 ms stddev 17.820\n</code></pre> <pre><code>progress: 600.0 s, 354.7 tps, lat 28.194 ms stddev 17.010\n</code></pre> <pre><code>transaction type: &lt;builtin: TPC-B (soort van)&gt;\n</code></pre> <pre><code>scaling factor: 10000\n</code></pre> <pre><code>query mode: simple\n</code></pre> <pre><code>number of clients: 10\n</code></pre> <pre><code>aantal threads: 4\n</code></pre> <p>duration: 600 s</p> <pre><code>aantal transacties dat daadwerkelijk verwerkt zijn: 205685\n</code></pre> <pre><code>average latency = 29.163 ms\n</code></pre> <pre><code>latency stddev = 22.633 ms\n</code></pre> <pre><code>tps = 342.771509 (including connection establishments)\n</code></pre> <pre><code>tps = 342.778836 (excluding connections establishing)\n</code></pre> <p>=================================================</p>"},{"location":"administrators-guide/troubleshooting/verify/#uitvoering","title":"Uitvoering","text":""},{"location":"architecture/mtls/","title":"mTLS","text":"<p>The building block uses certificates for encryption of network traffic (server certificates) and for authentication (client certificates). For situations where one chain is comprised of both client and server certificates, this is called mTLS.</p>"},{"location":"architecture/mtls/#chainsmith","title":"chainsmith","text":"<p>The default option is to use chainsmith to create a single chain for every new cluster. The chain contains</p> <ul> <li>a freshly created root certificate</li> <li>2 intermediates, server and client, both signed by the root</li> <li>a server certificate for every server that the cluster is comprised of, all of them signed by the server intermediate</li> <li>client certificates for every service requiring certificate authentication, all of them signed by the client intermediate</li> </ul>"},{"location":"architecture/mtls/#bring-your-own","title":"Bring your own","text":"<p>As an alternative you have the option to generate your own certificates from your own intermediate.</p> <p>Note</p> <p>Signing client certificates by your root certificate brings down security, and is not advised</p>"},{"location":"architecture/mtls/#background-information","title":"Background information","text":"<ul> <li>Background information about the tool:\u00a0chainsmith</li> </ul>"},{"location":"architecture/overview/","title":"Overview","text":""},{"location":"architecture/overview/#what-pgvillage-is-not","title":"What PgVillage is NOT","text":"<p>Imagine a large (capital?) city. So much traffic, so much noise, so much going on,too much to follow. There is zero trustworthyness, but Everybody has access, nobody has oversight or control, and everybody seems annonymous, untrustworthy, and to be there for their own benefit. The streets are filthy, the river enters the city heavilly poluted, and leaves the city even more poluted. (note: we love cities, just trying to ppaiint a picture ;) ).</p> <p>Now imagine your database solutions to be resembled by this city, the data being resembled by the data. And you know what PgVillage is not. PgVillage is the very opposite.</p>"},{"location":"architecture/overview/#what-pgvillage-is","title":"What PgVillage IS","text":"<p>With PgVillage, everything is calm, the data that enters should be clean, or at least it stands out as being dirty because of the input, not because of the infrastructure itself. There has been put a lot of effort into authorization:</p> <ul> <li>Peer (your neighbour) if you can</li> <li>cert (thrusted by a thrustworthy 3rd party, with all papers in place) for everything your neighbor cannot help</li> <li>LDAP, Kerberos, oAuth for maintenance guys, bt only those that should have access. And they are still someone your probably know on a personal level</li> </ul> <p>PgVillage offers a robust architecture, with state of the art infrastructure, such as</p> <ul> <li>Stolon relying on etcd for High Availability</li> <li>WAL-g and minio for backup</li> <li>Prometheus / Grafana for metrics, alerts and dashboards</li> <li>Properly connect to PostgreSQL</li> <li>with Client Connection Failover if you can, or</li> <li>with stolon-proxy which always points at the current pimary, or</li> <li>use a proxy with pgroute66, haproxy and optionally keepalived for VIP management if you want.</li> <li>PgQuartz for PostgreSQL miantenance</li> <li>Implement federated authorization (ldap sync), and manage the resources such as databases, extensions, users, roles, etc. with pgfga</li> <li>With PgVillage you are in control of how you leverage the power of PostgreSQL.   Run your favorite distribution, deploay and maintain with ease, use the Power of PostgreSQL with Foreign Data Wrappers such as db2_fdw</li> </ul> <p>With PgVillage you keep your data in a safe, trustworthy place. No Vendor Lockin, no corporate suits chasing you for money, just support when you need it and for what you need it. With PgVillage you are relaxed, healthy, in control, and happy.</p>"},{"location":"architecture/overview/#design","title":"Design","text":""},{"location":"architecture/pg_service/","title":"postres services","text":"<p>Connecting to Postgres may require a lot of configuration, including user, database, multiple hosts, connection parameters, etc.</p> <p>Note</p> <p>Please don;t configure passwords clear text in configuration files!!!</p> <p>PostgreSQL clients can be used with a pg_service.conf file to configure services, where every service represents a connection with different setting.</p> <p>PgVillage creates a ~postgres/pg_service.conf file whichh conatins all types of connections that the linux user for the postgres service could require.</p> <p>Example</p> <p>[local] host=/tmp port=5432</p> <pre><code>[proxy]\nhost=127.0.01\nport=25432\nsslmode=verify-full\n\n[master]\nhost=host1.mydomain.org,host2.mydomain.org,host3.mydomain.org\nport=5432\ntarget_session_attrs=read-write\nsslmode=verify-full\n\n[standby]\nhost=host1.mydomain.org,host2.mydomain.org,host3.mydomain.org\nport=5432\ntarget_session_attrs=read-write\n</code></pre>"},{"location":"architecture/pg_service/#background","title":"Background","text":"<p>For more information, please refer to PostgreSQL docs.</p>"},{"location":"archive/openssl_client_certs/","title":"Openssl client certs","text":"<p>Note: For automation and reproducibility, ChainSmith is used. and Documentation Generate and Roll Out New Certificates</p>"},{"location":"archive/openssl_client_certs/#introduction","title":"Introduction","text":"<p>Binnen deze bouwsteen worden client certificaten gebruikt voor authenticatie van postgres users.</p> <p>Client certificaat authenticatie heeft als voordeel dat het certificaat en de key niet op de PostgreSQL database servers bekend hoeft te zijn.</p> <p>PostgreSQL gebruikt een root certificaat om de betrouwbaarheid van het client certificaat te controleren.</p> <p>Dat kan (als het intermediate met de sleutel bewaard is) ook achteraf nieuwe certificaten worden uitgegeven.</p> <p>Further, each client certificate is issued for a specific user, making it harder to remember and copy, and requiring server TLS.</p> <p>Het is dus een veiligere oplossing. Het vereist echter ook een hoger kennis niveau, met name in beheer.</p>"},{"location":"archive/openssl_client_certs/#benodigdheden","title":"Benodigdheden","text":"<p>Om met client certificaten te kunnen authentiseren is het volgende nodig:</p> <ul> <li>A TLS connection. That means:</li> <li><code>hostssl</code> in the HBA file</li> <li><code>ssl=on</code> within PostgreSQL</li> <li>a valid server certificate<ul> <li>not expired</li> <li>corresponding to the server FQDN</li> </ul> </li> <li>a root certificate on the client that trusts the server certificate</li> <li>A valid client certificate</li> <li>not expired</li> <li>corresponding to the user who is logging in</li> <li>A root certificate on the PostgreSQL database server that trusts the client certificate</li> <li>A rule in the PostgreSQL HBA file that prescribes certificates as an authentication method for this communication</li> <li>Managed with Ansible: <code>environments/[ENVIRONMENT]/group_vars/all/generic.yml</code></li> <li>Example:</li> </ul> <p>hostssl cmdbvm cmdb 10.0.6.188/32 cert</p> <p>Note: Both <code>hostssl</code> and <code>cert</code> are required.</p> <ul> <li>The rule must be the first one that applies (not under another rule with a different method).</li> </ul>"},{"location":"archive/openssl_client_certs/#reference-material","title":"Reference material","text":"<p>Note: This is reference documentation. Use Chainsmith and the generate and roll out new certificates documentation</p> <p>Voor het genereren van client certificaten is alleen een recente versie van openssl nodig.</p> <p>Verder beschrijft deze WI alle stappen die nodig zijn voor het genereren van een nieuwe chain.</p> <p>The WI is inspired by, among other things:</p> <pre><code>[https://www.makethenmakeinstall.com/2014/05/ssl-client-authentication-step-by-step/](https://www.makethenmakeinstall.com/2014/05/ssl-client-authentication-step-by-step/)\n</code></pre>"},{"location":"archive/openssl_client_certs/#aanmaken-ca","title":"Aanmaken CA","text":"<p>certificaten worden altijd ondertekend door een ander certificaat.</p> <p>Voor server certificaten kan dit extern signed worden met een lange chain van intermediate certs.</p> <p>En in andere situaties kan een certificaat self signed zijn.</p> <p>Voor client certificaten is het nodig dat er een CA is.</p> <p>And for our application, an intermediate actually has little added value.</p> <p>We gaan daarom een CA maken die direct client certificaten kan ondertekenen.</p> <p>On the system with OpenSSL:</p> <p># Go to a new folder. Here come the temporary certificates and private keys:</p> <p>cd$(mktemp -d)</p>"},{"location":"archive/openssl_client_certs/#copy-etcpkitlsopensslcnf-into-this-folder","title":"Copy <code>/etc/pki/tls/openssl.cnf</code> into this folder:","text":"<p>cp /etc/pki/tls/openssl.cnf ./ca.cnf</p> <p>Then adjust the following in the locally copied <code>ca.cnf</code>:</p> <pre><code>[Your specific changes here]\n</code></pre> <ul> <li>In the chapter [ req ], it must:</li> <li>remove an existing option: <code>attributes = req_attributes</code></li> <li>add a new option: <code>prompt = no</code></li> <li>The entire existing content in the chapter [ req_distinguished_name ] can be replaced with:</li> </ul> <pre><code>CN = **[REPLACED BY VIP HOSTNAME FOR API OR POSTGRES]**\n</code></pre> <p>C = NL</p> <p>UT = Utrecht</p> <pre><code>L = Bilthoven\n</code></pre> <pre><code>= \u00a0National Institute for Public Health and the Environment (Acme)\n- In the chapter `[usr_cert]`, `nsCertType = client, email` must be set\n</code></pre> <p>Example diff:</p> <p>diff /etc/pki/tls/openssl.cnf ca.cnf</p> <p>110d109</p> <p>&lt; attributes \u00a0= req_attributes</p> <p>111a111</p> <pre><code>&gt; prompt = no\n</code></pre> <p>129,156c129,133</p> <pre><code>countryName = Landnaam (2 letters code)\n</code></pre> <pre><code>&lt;countryName_default = XX&gt;\n</code></pre> <pre><code>&lt; countryName_min = 2 &gt;\n</code></pre> <pre><code>&lt; countryName_max \u00a0 \u00a0 = 2 &gt;\n</code></pre> <p>&lt;</p> <pre><code>&lt;stateOrProvinceName&gt; = State or Province Name (full name)\n</code></pre> <pre><code># stateOrProvinceName_default = Default Province\n</code></pre> <p>&lt;</p> <p>&lt; localityName \u00a0\u00a0= Locality Name (eg, city)</p> <pre><code>&lt;localityName_default = Default City&gt;\n</code></pre> <p>&lt;</p> <pre><code>&lt; 0.organizationName = Organization Name (e.g., company)\n</code></pre> <pre><code>&lt; 0.organizationName_default = Default Company Ltd&gt;\n</code></pre> <p>&lt;</p> <pre><code># We can do this, but it's not usually necessary :-)\n</code></pre> <pre><code>#1.organizationName = Second Organization Name (e.g., company)\n</code></pre> <pre><code>#1.organizationName_default = World Wide Web Pty Ltd\n</code></pre> <p>&lt;</p> <pre><code>organizationalUnitName = Organizational Unit Name (e.g., section)\n</code></pre> <pre><code># organizationalUnitName_default =\n</code></pre> <p>&lt;</p> <pre><code>commonName = Common Name (e.g., your name or your server's hostname)\n</code></pre> <pre><code>&lt; commonName_max \u00a0\u00a0= 64 &gt;\n</code></pre> <p>&lt;</p> <pre><code>emailAddress = Email Address\n</code></pre> <pre><code>emailAddress_max = 64\n</code></pre> <p>&lt;</p> <pre><code># SET-ex3 = SET extension number 3\n</code></pre> <p>---</p> <pre><code>&gt; CN = acme-vbepr-v01a.acme.corp.com\n</code></pre> <pre><code>&gt; C = NL\n</code></pre> <pre><code>ST = Utrecht\n</code></pre> <p>L = Bilthoven</p> <p>O = National Institute for Public Health and the Environment (Acme)</p> <p>184c161</p> <pre><code># nsCertType = client, email\n</code></pre> <p>---</p> <pre><code>nsCertType = client, email\n</code></pre> <p>Then the root certificate can be created:</p> <p>openssl req -newkey rsa:4096 -nodes -keyform PEM -keyout ca.pem -x509 -days 3650 -outform PEM -out ca.cer -config ca.cnf</p> <p>Generating a 4096 bit RSA private key</p> <p>.........................................................++</p> <p>.................................++</p> <pre><code>generating a new private key and saving it to 'ca.pem'\n</code></pre> <p>-----</p>"},{"location":"archive/openssl_client_certs/#aanmaken-van-een-client-certificaat","title":"Aanmaken van een client certificaat","text":"<p>Take care:</p> <pre><code>- For Postgres: Create a client certificate for every user who logs in with client certificates. Use the username as CN in the config file:\n  - postgres\n  - avchecker\n  - pgquartz\n  - pgfga\n</code></pre> <p>For each client, a separate request must be made. Example for <code>pgrep_user</code>:</p>"},{"location":"archive/openssl_client_certs/#copy-the-config-and-adjust-cn-to-the-username","title":"Copy the config and adjust CN = ... to the username","text":"<pre><code>sed 's/CN \\*=.* /CN = pgquartz/ ' ca.cnf &gt; pgquartz.cnf\n</code></pre> <p># Generate a new private key:</p> <p>openssl genrsa -out pgquartz.key 4096</p>"},{"location":"archive/openssl_client_certs/#generate-a-new-csr","title":"Generate a New CSR","text":"<pre><code>openssl req -new -key pgquartz.key -out pgquartz.req -config pgquartz.cnf\n</code></pre> <p># Sign the certificate (fill in your own made-up password from step 1)</p> <p>openssl x509 -req -in pgquartz.req -CA ca.cer -CAkey ca.pem -set_serial 101 -extensions client -days 365 -outform PEM -out pgquartz.crt</p>"},{"location":"archive/openssl_client_certs/#distribution","title":"Distribution","text":"<p>Use the documentation for Generate and Roll Out New Certificates</p>"},{"location":"archive/openssl_server_certs/","title":"Openssl server certs","text":"<p>Note: For automation and reproducibility, ChainSmith is used.</p>"},{"location":"archive/openssl_server_certs/#introduction","title":"Introduction","text":"<p>Binnen deze bouwsteen worden server certificaten gebruikt voor identificatie van postgres database servers.</p> <p>Dit heeft als voordeel dat de client met abslute zekerheid weet dat de communicatie direct et de database server plaats vindt.</p> <p>Furthermore, the traffic is encrypted in such a way that only the client and server know about the communication (TLS in transit).</p> <p>The PostgreSQL client uses a root certificate to verify the trustworthiness of the PostgreSQL database server.</p>"},{"location":"archive/openssl_server_certs/#requirements","title":"Requirements","text":"<p>To be able to authenticate with client certificates, the following is needed:</p> <ul> <li>hostssl in the hba file</li> <li>ssl=on within postgres</li> <li>a valid server certificate</li> <li>not yet expired</li> <li>matching the server FQDN</li> <li>a root certificate on the client that trusts the server certificate</li> </ul>"},{"location":"archive/openssl_server_certs/#how-it-works","title":"How it works","text":""},{"location":"archive/openssl_server_certs/#why-san-certificates","title":"Why SAN Certificates?","text":"<p>For the FrontEnd, a SAN certificate is not required, but it's still nice to have one.</p> <p>Het primaire verkeer komt binnen op de VIP en derhalve moet de CN van het certificaat overeenkomen met de CN van de VIP.</p> <p>The VIP can be linked to two hosts and on both hosts, HAProxy ensures that the traffic is balanced across two other hosts.</p> <p>Since the API can be called via the VIP, but also on the hostnames of the 4 hosts, the certificate should actually have all 4 hosts as alternate names.</p> <p>For Postgres certificates, there are more types of traffic and also traffic directed towards hosts. In fact:</p> <ul> <li>Most of the traffic comes in on the VIP.</li> <li>However, there is also replication traffic to the master and to the cascading standby.</li> <li>There is also traffic from PgBouncer (on the proxies) to the master database server.</li> <li>Connecting to the VIP means that you are transparently connected at the TCP level to:</li> <li>Postgres on the RW part (5432)</li> <li>Postgres on the RO part (5433)</li> <li>PgBouncer on the RO part (6433)</li> </ul> <p>This means, for example, that a connection on VIP:5432 sees the same certificate as a replication connection on MASTER:5432 (and those are different hostnames).</p> <p>It is possible to make (part of) the traffic accept a certificate with an incorrect CN, but it's better to use a SAN certificate. <pre><code>### For which hosts?\n\nThe following certificates need to be applied for:\n\n---\n\n1. A certificate for PostgreSQL traffic (backend) for the following CN/Alternatives:\n</code></pre></p> <p>De huidige chainsmith configuratie genereert aparte certificaten voor iedere host.</p> <p>This can be with Ansible inventory adjustments 1 certificate    - VIP (CN)    - Backend Proxy 1 and 2 (Alternative)    - All postgres servers (Alternative)  </p> <ol> <li>A certificate for the backup server. This traffic is actually completely separated, but the existing automation for certificate chains is reused to also create this chain.</li> </ol>"},{"location":"archive/openssl_server_certs/#hoe-de-csr-aanmaken","title":"Hoe de CSR aanmaken","text":"<p>Note: This is reference documentation. Use Documentatie uitrollen nieuwe certificaten</p> <p>As a basis, the procedure used is found on this link.</p> <pre><code>1: Create a configuration file for OpenSSL. Save this as req.conf.\n</code></pre> <p>Voorbeelden in het volgende hoofdstuk</p> <p>2: Generate the CSR and the private key:</p> <p># Generate</p> <pre><code>openssl req -new -out company_san.csr -newkey rsa:4096 -nodes -sha256 -keyout company_san.key.temp -config req.conf\n</code></pre>"},{"location":"archive/openssl_server_certs/#convert-the-key-into-pkcs1","title":"Convert the key into PKCS#1","text":"<pre><code>openssl rsa -in company_san.key.temp -out company_san.key\n</code></pre> <p># Zet de CSR in leesbaar formaat in een file ernaast</p> <pre><code>openssl req -text -noout -verify -in company_san.csr &gt; company_san.csr.txt\n</code></pre> <p>Or a simple little script:</p> <pre><code># In the Folder with the Configuration Files:\n</code></pre> <pre><code># cat generate.sh\n</code></pre>"},{"location":"archive/openssl_server_certs/#binbash","title":"!/bin/bash","text":"<pre><code>ENDPOINT=${1:-unknown}\n</code></pre> <pre><code>`-f ${ENDPOINT}.conf || echo \"${ENDPOINT}.conf does not exist\"; exit 1`\n</code></pre> <pre><code>openssl req -new -out ${ENDPOINT}.csr -newkey rsa:4096 -nodes -sha256 -keyout ${ENDPOINT}.key.temp -config ${ENDPOINT}.conf\n</code></pre> <pre><code>openssl req -text -noout -verify -in ${ENDPOINT}.csr &gt; ${ENDPOINT}.csr.txt\n</code></pre> <pre><code>openssl rsa -in ${ENDPOINT}.key.temp -out ${ENDPOINT}.pem\n</code></pre> <pre><code>sed 's/^/        /'${ENDPOINT}.pem\n</code></pre> <p># Call:</p> <p>./generate.sh abackend</p> <p>./generate.sh afrontend</p> <p>./generate.sh awitness</p> <pre><code>3: Store the private key in Ansible Vault\n</code></pre> <ul> <li>Located in <code>vault/certs/</code></li> <li>Most are symlinks.</li> <li>You need the <code>acme-vbepr-v*.acme.corp.com.yml</code> and the <code>acme-vberm-l01*.acme.corp.com.yml</code>.</li> <li>Open with <code>ansible-vault edit [file]</code></li> <li>Pay attention to the alignment (2 spaces) under <code>private_ssl_key</code>.</li> </ul> <pre><code>4: Create a JIRA ticket with the details:\n</code></pre> <ul> <li>With label BI-CIF-SERVICES</li> <li>With the CSR (company_san.csr and company_san.csr.txt)</li> <li>With a description of what the CSR is for</li> </ul>"},{"location":"archive/openssl_server_certs/#deploy-certificates","title":"Deploy Certificates","text":"<pre><code>Note: This is reference documentation. Use [Chainsmith](../../../../../../../../../pages/xwiki/Infrastructuur/Team%3A+DBA/Werkinstrukties/Postgres/Bouwsteen/Chainsmith/WebHome.html)...\n</code></pre> <pre><code>1. Save the certificates in Ansible Vault as well  \n   - Certificates themselves are located in `vault/certs/`  \n   - Most files there are symlinks.  \n   - You need the `acme-vbepr-v*.acme.corp.com.yml` and `acme-vberm-l01*.acme.corp.com.yml`  \n   - Open with `ansible-vault edit [file]`  \n   - Pay attention to the alignment (2 spaces) under `public_ssl_key`.  \n   - Enter the certificate, followed by the certificates from the chain. The root certificate at the bottom can be omitted.  \n\n2. If necessary, also update the root certificate  \n   - Found in `\"environments/000_cross_env_vars\"` as key `postgres_root_cert`  \n   - It is placed correctly for all PostgreSQL clients  \n   - This should contain the root certificate of the chain. This would be the lowest one from the chain (omitted at point 1).  \n\n3. Deploy via Ansible. Steps: pgbouncer, postgres, and nginx.  \n   - Everything should be automatically reloaded if done correctly, but manual reloading may still be necessary.\n</code></pre>"},{"location":"archive/openssl_server_certs/#tips-and-tricks","title":"Tips and Tricks","text":"<p>See OpenSSL for commands for verification.</p>"},{"location":"archive/openssl_server_certs/#examples-recconf","title":"Examples <code>rec.conf</code>","text":"<p><pre><code>Warning: This is reference documentation. Use [Chainsmith](../../../../../../../../../pages/xwiki/Infrastructuur/Team%3A+DBA/Werkinstrukties/Postgres/Bouwsteen/Chainsmith/WebHome.html)...\n</code></pre> <pre><code>#### BackEnd in A\n\n\\[req\\]\n\n`distinguished_name = req_distinguished_name`\n\n---\n\n```markdown\nreq_extensions=v3_req\n</code></pre></p> <p>no prompt</p> <pre><code>[request distinguished name]\n</code></pre> <p>C=NL</p> <p>UTRECHT</p> <p><code>L = Bilthoven</code></p> <p>= National Institute for Public Health and the Environment (Acme)</p> <pre><code>CN=acme-vbepr-v01a.acme.corp.com\n</code></pre> <p><code>[v3_req]</code></p> <pre><code>keyUsage = keyEncipherment, dataEncipherment\n</code></pre> <pre><code>extendedKeyUsage=serverAuth\n</code></pre> <pre><code>subjectAltName = @alt_names\n</code></pre> <p>[alt_names]</p> <pre><code>DNS.1=acme-vbepr-server1.acme.corp.com\n</code></pre> <p>DNS.2=acme-vbepr-server2.acme.corp.com</p> <pre><code>DNS.3=acme-vbedb-server1.rivv.corp.com\n</code></pre> <pre><code>DNS.4=acme-vbedb-server2.acme.corp.com\n</code></pre> <p>DNS.5=acme-vbedb-server3.acme.corp.com</p> <pre><code>DNS.6=acme-vbedb-server4.acme.corp.com\n</code></pre> <pre><code>DNS.7= acme-vbedb-server5.acme.corp.com\n</code></pre> <pre><code>DNS.8=acme-vbedb-server6.rivv.corp.com\n</code></pre>"},{"location":"developers-guide/developing/","title":"Introduction","text":"<p>Deze documentatie beschrijft hoe evenuele nieuwe features kunnen worden toegevoegd.</p>"},{"location":"developers-guide/developing/#dependencies","title":"Dependencies","text":"<ul> <li>For expansion of the SBB, consider looking at the community project PgVillage, where developments are continuing.</li> <li>For personal expansions (from Acme), adjustments to the code should be made through Ansible Development.</li> <li>For the personal code (from Acme), see:\u00a0https://gitlab.int.corp.com/gurus-db-team/ansible-postgres/-/tree/dev/</li> </ul>"},{"location":"developers-guide/developing/#development","title":"Development","text":"<p>This works through the following steps:</p> <ol> <li> <p>Product Ownership</p> </li> <li> <p>Why is the new feature needed</p> </li> <li>How much can it cost in development and operation</li> <li> <p>What is expected of it (availability, Open Source, support options, etc.)</p> </li> <li> <p>Solution Design</p> </li> <li> <p>What solutions are there</p> </li> <li> <p>Which has preference</p> </li> <li> <p>Proof of Concept (POC)</p> </li> <li> <p>Build it in the POC environment</p> </li> <li> <p>Automation</p> </li> <li> <p>Ansible role</p> </li> <li>Ansible environment adjustments</li> <li> <p>Roll out where desired</p> </li> <li> <p>Management</p> </li> <li> <p>Documentation</p> </li> <li>Transfer to the management team</li> <li> <p>Availability service</p> </li> <li> <p>Support</p> </li> <li>Investigate support options, support wishes and acquire it</li> </ol>"},{"location":"developers-guide/vagrant/","title":"Vagrant","text":""},{"location":"developers-guide/vagrant/#part-of-a-component","title":"Part of a component","text":"<p>Bouwblok Postgresql</p>"},{"location":"developers-guide/vagrant/#introduction","title":"## Introduction","text":"<p>Om PostgreSQL te installeren wordt gebruik gemaakt van Ansible.</p> <p>For developing playbooks and roles, it's handy to use a local environment.</p> <p>dit kan middels Virtuele machines op eigen laptop.</p> <p>VirtualBox is a popular tool for running virtual machines (VMs).</p> <p>Vagrant is a tool that provides a command-line interface (CLI) for interacting with VirtualBox and virtual machines (VMs).</p>"},{"location":"developers-guide/vagrant/#markdown","title":"```markdown","text":"<p>Requirements and Dependencies <pre><code>For using Vagrant and VirtualBox, these programs must first be installed on a local laptop.\n\nOm Ansible playbooks te runnen is Ansible nodig.\n\nSo:\n\n- Ansible\n\n- VirtualBox\n\n- Vagrant\n\n\\- Git\n\n## Uitvoering\n\nTo roll out a few VMs using Vagrant, a `Vagrantfile` is needed.\n\nLogging into these VMs using SSH keys requires an SSH key pair.\n\nCreate this and then place it next to the Vagrantfile in the same directory:\n\ncreate directory: `mkdir ~/Virtualmachines`\n\ncreate a key pair:\n\n```shell\nssh-keygen -t rsa -b &lt;size&gt; -f ~/Virtualmachines/id_rsa\n</code></pre></p> <pre><code>maak Vagrantfile aan met onderstaande vulling\u00a0 ( deze maakt 7 VM's aan, pas eventueel aan naar behoefte ):\n\n```ruby\nVagrant.configure(\"2\") do |config|\n</code></pre>"},{"location":"developers-guide/vagrant/#base-vm-os-configuration","title":"Base VM OS configuration.","text":"<pre><code># config.vm.box = \"generic/rhel8\"\n</code></pre> <pre><code># config.vm.box = \"bento/rockylinux-8\"\n</code></pre> <pre><code>config.vm.box = \"bento/ubuntu-20.04\"\n</code></pre> <pre><code>config.vm.synced_folder '.', '/vagrant', disabled: true\n</code></pre> <pre><code>config.ssh.insert_key = false\n</code></pre> <pre><code>config.vm.provider :virtualbox do |v|\n</code></pre> <p>v.memory = 2048</p> <p><code>vcpus = 4</code></p> <pre><code># v.linked_clone = true\n</code></pre> <p>end</p>"},{"location":"developers-guide/vagrant/#define-three-vms-with-static-private-ip-addresses","title":"Define three VMs with static private IP addresses.","text":"<p>boxes = [</p> <p>{ :name =&gt; \"server1.example.com\", :ip =&gt; \"192.168.56.11\" },</p> <p>{ :name =&gt; \"server2.example.com\", :ip =&gt; \"192.168.56.12\" },</p> <pre><code>{ name: \"server3.example.com\", ip: \"192.168.56.13\" },\n</code></pre> <pre><code>{ name: \"server4.example.com\", ip: \"192.168.56.14\" },\n</code></pre> <pre><code>{ \"name\": \"server5.example.com\", \"ip\": \"192.168.56.15\" },\n</code></pre> <pre><code>{:name =&gt; \"server6.example.com\", :ip =&gt; \"192.168.56.16\"},\n</code></pre> <pre><code>{ name: \"server7.example.com\", ip: \"192.168.56.17\" }\n</code></pre> <p>]</p> <pre><code>if Vagrant.has_plugin?('vagrant-registration')\n</code></pre> <pre><code>config.registration.username = 'mailaddress@hcs-company.com'\n</code></pre> <pre><code>config.registration.password = 'password_redhat.com'\n</code></pre> <p>end</p>"},{"location":"developers-guide/vagrant/#allocate-resources-for-each-of-the-virtual-machines","title":"Allocate resources for each of the virtual machines.","text":"<pre><code>boxes.each do |opts|\n</code></pre> <pre><code>config.vm.define opts[:name] do |config|\n</code></pre> <pre><code>config.vm.hostname = opts[:name]\n</code></pre> <pre><code>config.vm.network :private_network, ip: opts[:ip]\n</code></pre> <pre><code>config.vm.provision \"file\", source: \"id_rsa\", destination: \"/home/vagrant/.ssh/id_rsa\"\n</code></pre> <pre><code>public_key = File.read(\"id_rsa.pub\")\n</code></pre> <pre><code>config.vm.provision :shell, inline: \"\n</code></pre> <pre><code>echo 'Copying Ansible VM public SSH keys to the VM'\n</code></pre> <pre><code>mkdir -p /home/vagrant/.ssh\n</code></pre> <p>chmod 700 /home/vagrant/.ssh</p> <pre><code>echo '#{public_key}' &gt;&gt; /home/vagrant/.ssh/authorized_keys\n</code></pre> <pre><code>chmod -R 600 /home/vagrant/.ssh/authorized_keys\n</code></pre> <pre><code>echo 'Host 192.168.*.*' &gt;&gt; /home/vagrant/.ssh/config\n</code></pre> <pre><code>echo 'StrictHostKeyChecking no' &gt;&gt; /home/vagrant/.ssh/config\n</code></pre> <pre><code>echo 'UserKnownHostsFile /dev/null' &gt;&gt; /home/vagrant/.ssh/config\n</code></pre> <p>chmod -R 600 /home/vagrant/.ssh/config</p> <p><code>, privileged: false</code></p> <p>end</p> <p>end</p> <p>end</p> <p>then run the following command:</p> <pre><code>vagrant up\n</code></pre>"},{"location":"tools/avchecker/","title":"Avchecker","text":"<p>Avchecker is a tool that monitors the availability of PostgreSQL.</p>"},{"location":"tools/avchecker/#how-it-works","title":"How It Works","text":"<ol> <li>It\u2019s a Python script.</li> <li>It connects to a database.</li> <li>It creates (if necessary) a table with one row.</li> <li>Then it endlessly repeats:</li> <li>Reads back the last value.</li> <li>Writes a new value.</li> <li>Checks if the time difference between the previous and new value is longer than 7.5 seconds (adjustable).</li> <li>If the difference exceeds this threshold, it reports to stdout.</li> </ol>"},{"location":"tools/avchecker/#architecture-overview","title":"Architecture Overview","text":"<p>Avchecker runs on all database servers as a service and monitors different connection endpoints:</p> <ul> <li>stolon \u2192 Direct connection to the master.</li> <li>proxy \u2192 Connection to the master through stolon-proxy.</li> <li>router \u2192 Connection via HAProxy on port 5432.</li> </ul>"},{"location":"tools/avchecker/#requirements-and-dependencies","title":"Requirements and Dependencies","text":"<p>Avchecker runs as a service with multiple instances per database server.</p>"},{"location":"tools/avchecker/#components","title":"Components","text":""},{"location":"tools/avchecker/#1-service-files","title":"1. Service Files","text":"<ul> <li>Location: <code>/etc/systemd/system/avchecker@.service</code> (Ansible managed)</li> <li>Instances:</li> <li><code>avchecker@stolon.service</code></li> <li><code>avchecker@proxy.service</code></li> <li><code>avchecker@routerro.service</code></li> <li><code>avchecker@routerrw.service</code></li> </ul>"},{"location":"tools/avchecker/#2-script","title":"2. Script","text":"<ul> <li>Path: <code>/opt/avchecker/avchecker.py</code> (Ansible managed)</li> <li>Python version: <code>3.6.8</code></li> </ul>"},{"location":"tools/avchecker/#3-linux-user","title":"3. Linux User","text":"<ul> <li>User: <code>avchecker</code> (Ansible managed)</li> <li>Authentication: Client certificates (Ansible managed)</li> </ul>"},{"location":"tools/avchecker/#4-table","title":"4. Table","text":"<ul> <li>Database: <code>postgres</code></li> </ul> <pre><code>CREATE TABLE public.avchecker (last timestamptz);\n</code></pre> <p>(Managed by Python script)</p>"},{"location":"tools/avchecker/#5-configuration-files","title":"5. Configuration Files","text":"<ul> <li><code>/etc/default/avchecker_proxy</code>(configuration for connections via stolon-proxy)</li> <li><code>/etc/default/avchecker_stolon</code>(configurations for direct connections to the master)</li> <li><code>/etc/default/avchecker_routerro</code>(configurations for connections via haproxy port 5433)</li> <li><code>/etc/default/avchecker_routerrw</code>(configurations for connections via haproxy port 5432)</li> </ul>"},{"location":"tools/avchecker/#6-connections","title":"6. Connections:","text":"<ul> <li>Each database server creates a connection for every Avchecker instance.</li> <li>A cluster with 4 nodes and a router results in 16 total connections, of which 12 connect to the master database.</li> </ul>"},{"location":"tools/avchecker/#7-endpoints","title":"7. Endpoints","text":"<ul> <li>stolon: direct connection to the master database on one of the nodes.</li> <li>proxy: direct connection to stolon-proxy, which forwards to the master database.</li> <li>routerrw:</li> <li>connection to HAProxy on port 5432</li> <li>from HAProxy to stolon-proxy on the master</li> <li>from stolon-proxy to the master</li> <li>routerro:</li> <li>connection to HAProxy on port 5433</li> <li>from HAProxy to one of the standby instances</li> </ul>"},{"location":"tools/avchecker/#usage","title":"Usage","text":"<p>The purpose of Avchecker is to monitor the connectivity and availability of the PostgreSQL service across different endpoints.</p>"},{"location":"tools/avchecker/#example-scenarios","title":"Example Scenarios","text":"<ul> <li> <p>If the router does not function properly or behaves inconsistently:</p> </li> <li> <p><code>avchecker@proxy</code> and <code>avchecker@stolon</code> do not provide notifications.</p> </li> <li> <p><code>avchecker@routerro</code> and <code>avchecker@routerrw</code> do provide notifications.</p> </li> <li> <p>If the application experiences issues but <code>avchecker@routerro</code> and <code>avchecker@routerrw</code> do not:</p> </li> <li> <p>The problem is most likely in the application, routing, or firewalling up to the router VIP.</p> </li> </ul> <p>This makes Avchecker an excellent diagnostic tool to determine at which level a connectivity issue exists.</p> <p>Avchecker runs continuously as a systemd service and reports any issues in the systemd journal.</p> <p>There is a small difference between the <code>routerro</code> service and the other services.</p>"},{"location":"tools/avchecker/#commands","title":"Commands","text":"<p>Status control works best via <code>journalctl</code> commands.</p> <pre><code>[root@acme-dvppg1db-server2 ~]# journalctl -efu avchecker@routerro | head\n</code></pre> <p>Example logs:</p> <pre><code>-- Logs begin at Sun 2022-10-16 02:26:36 CEST. --\n\nOct 16 00:38:06 acme-dvppg1db-server2 avchecker.py[629825]: cannot execute UPDATE in a read-only transaction\n\nOct 16 03:38:06 acme-dvppg1db-server2 avchecker.py[629825]: cannot execute UPDATE in a read-only transaction\n\nOct 16 03:38:06 acme-dvppg1db-server2 avchecker.py[629825]: cannot execute UPDATE in a read-only transaction\n\nOct 16 03:06:38 acme-dvppg1db-server2 avchecker.py[629825]: cannot execute UPDATE in a read-only transaction\n\nOct 16 02:38:06 acme-dvppg1db-server2 avchecker.py[629825]: cannot execute UPDATE in a read-only transaction\n\nOct 16 02:52:16 acme-dvppg1db-server2 avchecker.py[629825]: cannot execute UPDATE in a read-only transaction\n\nOct 1602:52:16 acme-dvppg1db-server2 avchecker.py[629825]: cannot execute UPDATE in a read-only transaction\n\nOct 16 05:02:16 acme-dvppg1db-server2 avchecker.py[629825]: cannot execute UPDATE in a read-only transaction\n\nOct 1602:52:16 acme-dvppg1db-server2 avchecker.py[629825]: cannot execute UPDATE in a read-only transaction\n</code></pre>"},{"location":"tools/avchecker/#proxy-service-example","title":"Proxy Service Example","text":"<pre><code>[root@acme-dvppg1db-server2 ~]# journalctl -efu avchecker@proxy\n\n#Logs begin at Sun 2022-10-16 02:26:36 CEST.\n\nOct 16 20:25:28 acme-dvppg1db-server2 avchecker.py[629455]: 0:00:08.314879\n\n[root@acme-dvppg1db-server2 ~]# journalctl -efu avchecker@stolon\n\n-- Logs begin at Sun 2022-10-16 02:26:36 CEST.\n\n[root@acme-dvppg1db-server2 ~]# journalctl -efu avchecker@routerrw\n\n-- Logs begin at Sun 2022-10-16 02:26:36 CEST.\n</code></pre> <p>At the first router, we observe a large number of notifications.</p> <p>This is expected behavior because updates fail on a standby instance \u2014 which is logical for <code>routerro</code>.</p> <p>It was decided to include these notifications in the output since they confirm that we are working against a standby instance.</p> <p>The downside is that there are more messages per second on stdout, causing the logs to fill up quickly. Hence the use of <code>| head 20</code>.</p> <p>Systemd handles this efficiently and is not significantly impacted.</p> <p>As an alternative, it can be decided, for example, to give a notification every n times and skip the rest.</p> <p>This feature is (for now) not implemented.</p> <p>For the proxy service, you see a notification:</p> <pre><code>Oct 16 20:25:28 acme-dvppg1db-server2 avchecker.py[629455]: 0:00:08.314879\n</code></pre> <p>This indicates that stolon-proxy took 8.31 seconds to reconnect and rewrite data. Possible causes:</p> <ul> <li>The stolon-proxy was restarted</li> <li>The query took longer than expected due to locking or load delays.</li> </ul> <p>All other services show no notifications.</p>"},{"location":"tools/avchecker/#controls","title":"Controls","text":"<p>If it\u2019s important to check availability, do the following steps.</p> <ul> <li>Log in to one of the database servers (preferably not the master)</li> <li>Check the output of <code>journalctl</code> for all available services</li> </ul>"},{"location":"tools/avchecker/#everything","title":"Everything","text":"<p>Run the following commands:</p> <pre><code>cat /var/log/syslog | grep 'avchecker\\|proxy'\njournalctl -efu avchecker@stolon\njournalctl -efu avchecker@routerrw\n</code></pre>"},{"location":"tools/avchecker/#verify-the-following","title":"Verify the Following","text":"<ul> <li>The services have few interruptions</li> <li>Only <code>routerro</code> should have many and recent rules, typically showing <code>cannot execute UPDATE in a read-only transaction</code>.</li> <li>All other interruptions are points to look at</li> <li>Interruptions from different services don't coincide</li> <li>If interruptions for all avchecker@ services coincide, there was likely an issue that the application also experienced</li> <li>An interruption for a single service probably indicates longer transaction times (postgres was busy) and is likely not noticed by the application</li> <li>The endpoint used by the application works properly</li> <li>Systems with a router config are probably routerw and routerro</li> <li>Systems without a router are likely stolon (direct to master)</li> <li>The routerro service has recent rules</li> <li>and only gives notifications for <code>cannot execute UPDATE in a read-oavchecker@routerronly transaction</code></li> <li>if there are no recent rules, it could be that the service is down or that the entire environment has been down for a long time. First check the avcheker@stolon service and all related controls.</li> </ul> <p>Note</p> <p>For a quick end-to-end check of PostgreSQL with a router, check the <code>@routerrw</code> and <code>@routerro</code> services.</p> <p>See at @routerrw and @routerro what to look out for\u2026</p>"},{"location":"tools/avchecker/#stolon","title":"@stolon","text":"<pre><code>journalctl -efu avchecker@stolon\n</code></pre> <p>If you encounter issues with <code>avchecker@stolon</code>, investigate and resolve them before proceeding</p> <p>Check whether there is a master available, if it can be reached from the current server, and ensure that the client certificates are functioning correctly (for example, they have not expired):</p> <pre><code>[postgres@acme-dvppg1db-server1 ~]$ psql service=master\n</code></pre>"},{"location":"tools/avchecker/#postgresql-1211","title":"PostgreSQL (12.11)","text":"<pre><code>SSL connection (protocol: TLSv1.3, cipher: TLS_AES_256_GCM_SHA384, bits: 256, compression: off)\n\nType \"help\" for help.\n\npostgres=# \\q\n\n[postgres@acme-dvppg1db-server1 ~]$\n</code></pre> <p>Connecting with <code>service=master</code> does the following:</p> <ul> <li>Connects one-to-one to all nodes and</li> <li>Performs a full SSL check (<code>sslmode=verify-full</code>)</li> <li>Authenticates with client certificates (for user <code>postgres</code>)</li> <li>Checks if it is a master instance</li> <li>Goes on to the next node if necessary</li> </ul> <p>If this works then you already know a lot:</p> <ul> <li>The server operates with a server certificate that can be verified with the root certificate (~postgres/.postgresql/root.crt).</li> <li>Client certificates are functioning correctly, can be verified by the server, and have not expired.</li> <li>NOTE: The entire chain expires simultaneously.</li> <li>NOTE: There is certificate monitoring for this certificate!</li> <li>A master instance is available.</li> </ul>"},{"location":"tools/avchecker/#proxy","title":"@proxy","text":"<p>The next step is the stolon-proxy layer. Check it with</p> <pre><code>journalctl -efu avchecker@proxy\n</code></pre> <p>If you notice issues with <code>avchecker@proxy</code>, resolve them before investigating <code>stolon-rw</code>.</p> <p>HAProxy connects through stolon-proxy, so issues with stOLON-PROXY also have consequences.</p> <p>If <code>avchecker@stolon</code> works properly, the best explanation is that the stolon-proxy service did not start correctly (or at all).</p> <p>Other issues may be related to firewalling (but the AvChecker also connects locally, and the stolon proxy connects to the master in the same way as the service=<code>stolon</code> check).</p> <p>Eventueel kan stolon-proxy ook gecontroleerd worden met psql:</p> <pre><code>[postgres@acme-dvppg1db-server1 ~]$ psql service=proxy\n</code></pre> <p>PostgreSQL (12.11)</p> <pre><code>SSL connection (protocol: TLSv1.3, cipher: TLS_AES_256_GCM_SHA384, bits: 256, compression: off)\n</code></pre>"},{"location":"tools/avchecker/#type-help-for-help","title":"Type \"help\" for help.","text":"<pre><code>postgres=# \\q\n\n[postgres@acme-dvppg1db-server1 ~]$\n</code></pre> <p>Connecting with <code>service=proxy</code> does the following:</p> <ul> <li>Connect locally to the stolon-proxy port</li> <li>Stolon-proxy forwards traffic to the master</li> <li>Performs full SSL verification (<code>sslmode=verify-full</code>)</li> <li>Authenticates with client certificates (for user <code>postgres</code>)</li> </ul> <p>If this works out then you already know a lot:</p> <ul> <li>The server operates with a server certificate that can be verified using the root certificate (~postgres/.postgresql/root.crt).</li> <li>The client certificates are functioning properly, can be verified by the server, and have not expired.</li> <li>NOTE: The entire chain expires simultaneously.</li> <li>NOTE: There is certificate monitoring for this certificate!!!</li> <li>A master instance is available.</li> <li>The local stolon-proxy can successfully connect to it.</li> </ul> <p>Read more information in the documentation of stolon.</p>"},{"location":"tools/avchecker/#routerrw","title":"@routerrw","text":"<p>Used when HAProxy + Keepalived + PgRoute66 are deployed.</p> <p>If <code>@stolon</code> and <code>@proxy</code> are healthy but <code>@routerrw</code> fails:</p> <ul> <li>The issue lies in router configuration (HAProxy, Keepalived, or PgRoute66).</li> </ul> <p>Refer to internal documentation for:</p> <ul> <li>HAProxy</li> <li>KeepaliveD</li> <li>PgRoute66</li> </ul> <p>The <code>@routerrw</code> service can also be very well used for an end-to-end check.</p> <p>The best tool for end-to-end control is the <code>@routerro</code> service, but it does not verify if the router also forwards to the primary database server.</p> <p>Therefore, @routerro should also be checked along with @routerrw:</p> <pre><code>journalctl -efu avchecker@routerrw\n</code></pre> <p>Check the output, ensuring that there are not (or very few) lines reporting a timeout.</p> <p>If you don't see any issues but find that insufficient, then check with the HAProxy documentation the output of the <code>show stat</code> command.</p>"},{"location":"tools/avchecker/#routerro","title":"@routerro","text":"<p>When a router configuration (using HAProxy, KeepaliveD and PgRoute66) is used, it is also monitored with the avchecker@routerrw service.</p> <p>If there are issues with <code>@stolon</code> and <code>@proxy</code>, it's best to resolve these first.</p> <p>If there are no issues from @stolon and @proxy, then the problem must be found in the router configuration.</p> <p>This can best be investigated and resolved with the documentation of keepalived, HAProxy and pgRoute66.</p> <p>The @routerro service can also be very well used for an end-to-end check.</p> <p>The main advantage of the <code>@routerro</code> service is that it continuously outputs status and covers all components.</p> <p>The result of this check immediately provides a lot of useful information.</p> <pre><code>journalctl -efu avchecker@routerro | head\n</code></pre> <p>Check the output, ensuring primarily that the router service provides recent rules (such as \"cannot execute UPDATE in a read-only transaction\") and nothing else.</p> <p>This tells you that:</p> <ul> <li>The router is still working properly.</li> <li>At least one of the other services is still updating the table.</li> <li>Streaming replication is still functioning (the other service updates the master and the changes reach this standby).</li> <li>The VIP is still linked to the server with a healthy HAProxy and pgrouter66 (i.e., the primary router is still working well).</li> <li>Server and client certificates are still working properly.</li> </ul>"},{"location":"tools/chainsmith/","title":"Chainsmith","text":"<p>Chainsmith is a community tool that can be configured with a simple YAML file to generate certificate chains.</p> <p>For more information, please refer to:</p> <ul> <li>mTLS</li> <li>Community repository: https://github.com/pgvillage-tools/chainsmith</li> </ul>"},{"location":"tools/chainsmith/#requirements-and-dependencies","title":"Requirements and Dependencies","text":"<p>Within the PostgreSQL deployment, we use Chainsmith as follows:</p> <ul> <li>We install chainsmith on the management server (and updates).</li> <li>We generate and distribute the certificates.</li> <li>When monitoring indicates that the certificates are about to expire, we regenerate and redistribute a new set of certificates.</li> </ul>"},{"location":"tools/chainsmith/#use","title":"Use","text":"<p>The PgVillage chainsmith tole takes care if installation, configuration, running and distributing the certificates.</p>"},{"location":"tools/etcd/","title":"Etcd","text":"<p>Etcd is a key-value store.</p> <p>Etcd consists of:</p> <ul> <li>an etcd service</li> <li>an etcdctl tool to read data from etcd via the command line</li> <li>an API that can be used by other tools (such as Stolon and PGQuartz) to read and use configuration</li> </ul>"},{"location":"tools/etcd/#prerequisites-and-dependencies","title":"Prerequisites and Dependencies","text":"<p>Within the PostgreSQL building block, etcd is used as the consensus mechanism for the cluster layer.</p> <p>Stolon uses etcd to store and distribute cluster-wide configuration, including:</p> <ul> <li><code>pg_hba.conf</code> configuration</li> <li><code>postgreSQL.conf</code> settings</li> <li>Cluster topology \u2014 which database is primary and which are standbys</li> </ul> <p>This configuration is consistently distributed across the entire cluster by etcd, which means:</p> <ul> <li>all nodes see the same configuration, or</li> <li>one or more nodes see that etcd is not available</li> </ul> <p>The stolon ensures that Postgres is available only when the configuration (consistent with consensus) is available for the stolon instance.</p> <p>In addition to stolon, both pgquart and WAL-G (<code>/opt/wal-g/scripts/backup_locked.sh</code>) also directly use etcd.</p>"},{"location":"tools/etcd/#operational-background-information","title":"Operational background information","text":""},{"location":"tools/etcd/#etcd-database-size","title":"Etcd database size","text":"<p>Etcd has its own internal database and retains old information. By default, etcd keeps the size of this database (with retention) to about 2.1 GB.</p> <p>This value can be adjusted in the etcd configuration. However, a larger database can impact etcd performance and, consequently, the availability of Stolon and PostgreSQL.</p> <p>We keep the default configuration.</p> <p>Note</p> <p>In the past, there were issues related to etcd database size. Since then, <code>ETCD_AUTO_COMPACTION_RETENTION</code> has been configured, and the setup has been stable. The following instructions are retained for historical reference and can be used for manual intervention if needed.</p> <p>If issues arise, the database can be manually reduced using compact and defragment commands.</p> <ol> <li>Check Etcd Service Status    If problems occur, check the status of the etcd service as follows:</li> </ol> <p>Example</p> <pre><code>[etcd@gurus-pgsdb-server1 ~]$ systemctl status etcd\n\u25cf etcd.service - Etcd Server\nLoaded: loaded (/etc/systemd/system/etcd.service; enabled; vendor preset: disabled)\nActive: active (running) since Tue 2022-01-19 14:58:39 CET; 2 months 21 days ago\nMain PID: 2142547 (etcd)\nTasks: 10 (limit: 49457)\nMemory: 344.0 MB\nCGroup: /system.slice/etcd.service\n\u2514\u25002142547 /usr/local/bin/etcd\n\nOct 10 10:07:16 gurus-pgsdb-server1 bash[2142547]: {\"level\":\"warn\",\"ts\":\"2022-07-26T11:07:49.311+0200\",\"caller\":\"clientv3/retry_interceptor.go:62\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"endpoint://client-02e576d1-d16f-4610-8fee-0586f7dbe4c1/127.0.0.1:2379\",\"attempt\":0,\"error\":\"rpc error: code = ResourceExhausted desc = etcdserver: mvcc: database space exceeded\"}\n</code></pre> <ol> <li>Check the Database Size and Alarm Status</li> </ol> <p>The size of the database can be queried as follows:</p> <p>Example</p> <pre><code># Requesting Status Endpoints:\netcdctl --write-out=table endpoint status\n\n# Request Alarm Status\netcdctl alarm list\n</code></pre> <ol> <li>Manual Compaction and Defragmentation</li> </ol> <p>This issue can be resolved by manually executing the following commands on all cluster members.</p> <p>Note</p> <p>This should not be executed on all members at the same time, as it affects the availability of etcd and, consequently, also that of PostgreSQL.</p> <p>Example</p> <pre><code># 1) Request an audit\netcdctl get mykey -w=json\n{\"header\":{\"cluster_id\":4788661511241613818,\"member_id\":336793577597500103,\"revision\":700518,\"raft_term\":26}}\n\n# 2) Compact Revision\n[etcd@gurus-pgsdb-server1 ~]$ etcdctl compact 700518\ncompacted revision 700518\n\n# 3) Defragment database\n[etcd@gurus-pgsdb-server1 ~]$ etcdctl defrag\n\n# 4) Remove All Alarms\n[etcd@gurus-pgsdb-server1 ~]$ etcdctl alarm disarm\n</code></pre>"},{"location":"tools/haproxy/","title":"HAProxy","text":"<p>The PostgreSQL component can optionally be deployed with a PostgreSQL router.</p> <p>The router consists of a high-availability (HA) setup with two servers, a virtual IP address, and HAProxy together with PgRoute66 running on both nodes.</p> <p>HAProxy is used to route TCP traffic to the appropriate PostgreSQL server(s), and PgRoute66 is used to direct HAProxy.</p>"},{"location":"tools/haproxy/#requirements","title":"Requirements","text":"<p>On the PostgreSQL router setup, the following components are required for HAProxy to function properly:</p> <ul> <li>The binary is rolled out using the (standard) haproxy rpm (from Satellite)</li> <li>The haproxyconfig can be found in <code>/etc/haproxy/haproxy.cfg</code> and is rolled out and managed via Ansible</li> <li>The haproxy config requires some hardcoded config in the Ansible inventory:<ul> <li><code>haproxy_rw_backends</code></li> <li><code>haproxy_ro_backends</code>   located in <code>environments/{ENV}/group_vars/all/generic.yml</code></li> </ul> </li> <li>HAProxy depends on a properly working PgRoute66</li> <li>The integration between HAProxy and PgRoute66 depends on the following scripts:</li> <li><code>/usr/local/bin/checkpgprimary.sh</code> (Ansible managed)</li> <li><code>/usr/local/bin/checkpgstandby.sh</code> (Ansible managed)</li> </ul>"},{"location":"tools/haproxy/#troubleshooting","title":"Troubleshooting","text":"<p>In principle, no management is required for HAProxy and PgRoute66.</p> <p>For troubleshooting, you can inspect active HAProxy connections using the following command:</p> <pre><code>[me@acme-dvppg1pr-server2 ~]$ echo \"show stat\" | sudo nc -U /var/lib/haproxy/stats | cut -d \",\" -f 1,2,5,6,18,37 | column -s, -t\n\npxname                    svname                                 scur  smax  status   check_status\nhaproxy-stat              FRONTEND                              0     0     OPEN     -\nPostgresReadWrite-frontend FRONTEND                              5     135   OPEN     -\nPostgresReadOnly-frontend  FRONTEND                              4     8     OPEN     -\nPostgresReadWrite-backend  acme-dvppg1db-server1.acme.corp.com   0     0     DOWN     PROCERR\nPostgresReadWrite-backend  acme-dvppg1db-server2.acme.corp.com   5     39    UP       PROCOK\nPostgresReadWrite-backend  acme-dvppg1db-server3.acme.corp.com   1     1     DOWN     PROCERR\nPostgresReadWrite-backend  acme-dvppg1db-server4.acme.corp.com   0     6     DOWN     PROCERR\nPostgresReadWrite-backend  BACKEND                              5     135   UP       -\nPostgresReadOnly-backend   acme-dvppg1db-server1.acme.corp.com   1     3     UP       PROCOK\nPostgresReadOnly-backend   acme-dvppg1db-server2.acme.corp.com   0     4     DOWN     PROCERR\nPostgresReadOnly-backend   acme-dvppg1db-server3.acme.corp.com   2     4     UP       PROCOK\nPostgresReadOnly-backend   acme-dvppg1db-server4.acme.corp.com   1     5     UP       PROCOK\nPostgresReadOnly-backend   BACKEND                              4     8     UP       -\n</code></pre> <p>From this output, you can conclude that:</p> <ul> <li>The primary database server <code>acme-dvppg1db-server2.acme.corp.com</code> is (UP and PROCOK for PostgresReadWrite-backend)</li> <li>Standby databases <code>acme-dvppg1db-server1.acme.corp.com</code>, <code>acme-dvppg1db-server3.acme.corp.com</code>, and <code>acme-dvppg1db-server4.acme.corp.com</code> are (UP and PROCOK for PostgresReadOnly-backend)</li> <li>There is not much traffic</li> <li>currently 5/4 connections for RW/RO</li> <li>maximum 135/8 for RW/RO</li> </ul>"},{"location":"tools/haproxy/#all-done","title":"All Done","text":"<p>Currently, all traffic is routed only to the primary node, via stolon-proxy on port 25432.</p> <ul> <li>Technically, this is convenient (no dual hop to a standby and then on to the primary)</li> <li>During switchover/failover, this means that the traffic will always come out at the primary</li> <li>However, this makes stolon-proxy on the primary node into a Single Point of Failure</li> </ul>"},{"location":"tools/keepalived/","title":"Keepalived","text":"<p>The PostgreSQL component can optionally be deployed with a PostgreSQL router.</p> <p>The router consists of a high-availability (HA) setup of two servers with a virtual IP address (VIP).</p> <p>This VIP is managed using Keepalived.</p>"},{"location":"tools/keepalived/#requirements","title":"Requirements","text":"<p>On the PostgreSQL router setup, the following components are required for Keepalived to function properly:</p> <ul> <li>The binary is rolled out using the (standard) Keepalived RPM (from Satellite).</li> <li>The Keepalived configuration can be found in <code>/etc/keepalived/keepalived.conf</code> and is deployed and managed via Ansible.</li> <li>The value for <code>virtual_router_id</code> should be unique per Keepalived cluster within a segment. This value is pseudo-randomly generated by Ansible.</li> </ul> <p>Important: Ensure that the router nodes are patched one at a time. After patching the first node, verify that it has fully recovered and the VIP is active before proceeding with the second node.</p>"},{"location":"tools/keepalived/#use","title":"Use","text":"<p>Keepalived is configured in balanced mode in this setup.</p> <p>This means both instances have the same priority, and no fallback is triggered when both nodes are available again.</p> <p>Under normal circumstances, both nodes will be available and one of the nodes will have been connected to the VIP (it is undetermined which one).</p> <p>Which VIP has been connected can be checked using the following command:</p>"},{"location":"tools/keepalived/#node-1","title":"Node 1","text":"<pre><code>me@gurus-dbabh-server1 ~/g/ansible-postgres (tmp)&gt; ssh acme-dvppg1pr-server1.acme.corp.com\n[me@acme-dvppg1pr-server1 ~]$ ip a\n\n1: lo: &lt;LOOPBACK, UP, LOWER_UP&gt; MTU 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n  link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n  inet 127.0.0.1/8 scope host lo\n    valid_lft forever preferred_lft forever\n\n2: ens192: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000\n  Link/Ethernet: 00:50:56:9d:54:47\n  Broadcast (brd): ff:ff:ff:ff:ff:ff\n  inet 10.0.4.*26/23 brd 10.0.4.455 scope global noprefixroute ens192\n    valid_lft forever\n    preferred_lft forever\n\n[me@acme-dvppg1pr-server1 ~]$ logout\nConnection to acme-dvppg1pr-server1.acme.corp.com closed.\n</code></pre>"},{"location":"tools/keepalived/#node-2","title":"Node 2","text":"<pre><code>me@gurus-dbabh-server1 ~/g/ansible-postgres (tmp) &gt; ssh acme-dvppg1pr-server2.acme.corp.com\n[me@acme-dvppg1pr-server2 ~\\]$ ip a\n\n1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n      valid_lft forever preferred_lft forever\n\n2: ens192: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000\n    link/ether 00:50:56:9d:79:5e brd ff:ff:ff:ff:ff:ff\n    inet 10.0.4.*27/23 brd 10.0.4.455 scope global noprefixroute ens192\n      valid_lft forever preferred_lft forever\n    inet 10.0.4.*28/23 scope global secondary ens192\n      valid_lft forever preferred_lft forever\n</code></pre> <p>In this example, node 2 has the extra VIP connected (2 IP addresses: 10.0.4.27 and 10.0.4.28) while node 1 does not (1 IP address: 10.0.4.*26).</p>"},{"location":"tools/keepalived/#todo","title":"ToDo","text":"<p>Keepalived could be provided with a script that checks if HAProxy, PgRoute66, and potentially even PostgreSQL behind HAProxy are accessible.</p> <p>This could perhaps further increase availability.</p> <p>In practice, however, an issue has never occurred that could have been prevented by this.</p>"},{"location":"tools/minio/","title":"MinIO","text":"<p>The standard building block makes backups using WAL-G and WAL-G stores the backups in Cloud Storage (buckets).</p> <p>Within Acme, however, there is no Cloud Storage available and therefore MinIO is deployed so that WAL-G can subsequently transport the backups to MinIO so that they:</p> <p>Note</p> <p>Note that using native Object storage from your Cloud provider, backup solution or storage solution is preferred over a VM withh Minio. This solution is only meant to provide an option whhen no other Object STorage solution is available.</p> <ul> <li>Stored outside the database server.</li> <li>All cluster nodes use a shared backup medium.</li> <li>The file system behind MinIO can be easily included in CommVault via VM Backup.</li> </ul> <p>This means that MinIO can be replaced by a future Cloud Storage (bucket) system once it becomes available within Acme.</p>"},{"location":"tools/minio/#requirements","title":"Requirements","text":"<p>For MinIO, the following components are required:</p> <ul> <li>MinIO and mcli are both run on a separate backup server (e.g., acme-dvppg1 bc-server1)</li> </ul>"},{"location":"tools/minio/#server","title":"Server:","text":"<ul> <li>The binary is deployed to /usr/local/bin/ using the RPMs</li> <li>Source for the minio RPM: https://dl.min.io/server/minio/release/linux-amd64</li> <li>The service file <code>/etc/systemd/system/minio.service</code> is created and maintained by Ansible</li> <li>The configuration <code>/etc/default/minio</code> is deployed and maintained by Ansible</li> <li>TLS certificates (<code>/etc/pki/tls/minio/*</code>) are deployed and maintained by Ansible</li> <li>The root certificate is made available to wal-g by Ansible</li> <li>Runs on port 9091 (default)</li> <li>Stores data in <code>/data/postgres/backup/</code></li> </ul>"},{"location":"tools/minio/#client-mcli","title":"Client (mcli):","text":"<ul> <li>Used by Ansible to create the bucket.</li> <li>Also configured by Ansible (under the <code>minio-server</code> user).</li> <li>The binary is deployed to <code>/usr/local/bin/</code> using the RPMs.</li> <li>Source for the mcli RPM: https://dl.min.io/client/mc/release/linux-amd64</li> </ul>"},{"location":"tools/minio/#usage","title":"Usage","text":"<p>In principle, everything is deployed and maintained through Ansible.</p> <p>If more insight is desired, two things can be done:</p> <p>1: Ensure routing to the management console (SSH proxy, opening ports in the firewall, etc.).</p> <p>You can then use a browser to connect to this port and browse through the bucket (MinIO).</p> <p>2: (Advice) Use <code>mcli</code> on the backup server under the <code>minio-user</code> account.</p> <pre><code>me@gurus-dbabh-server1 ~/g/ansible-postgres (tmp)&gt; ssh acme-dvppg1bc-server1.acme.corp.com\n\n#Last login: Thu Oct 13 21:12:47 2022 from 10.0.6.100\n\n[me@acme-dvppg1bc-server1 ~] $ sudo -i uminio-user\n\n[minio-user@acme-dvppg1bc-server1 ~]$ /usr/local/bin/mcli ls minio/backup/basebackups_005/\n\n[2022-10-11 16:54:12 CEST] 404B STANDARD base_000000010000000C0000000E_backup_stop_sentinel.json\n\n[2022-10-12 09:08:48 CEST]  530B STANDARD base_000000010000000E00000069_D_000000010000000C0000000E_backup_stop_sentinel.json\n\n[2022-10-12 09:29:37 CEST] 404B STANDARD base_000000010000000E0000006B_backup_stop_sentinel.json\n\n[2022-10-12 20:02:06 CEST]   528B STANDARD base_000000010000000E0000006E_D_000000010000000E0000006B_backup_stop_sentinel.json\n\n[2022-10-13 20:02:17 CEST]   559B STANDARD base_000000010000001000000046_D_000000010000000E0000006E_backup_stop_sentinel.json\n\n[2022-10-13 21:31:56 CEST]    0B base_000000010000000C0000000E/\n\n[2022-10-13 21:31:56 CEST] \u00a0\u00a0\u00a0\u00a00B base_000000010000000E00000069_D_000000010000000C0000000E/\n\n[2022-10-13 21:31:56 CEST]    0B base_000000010000000E0000006B/\n\n[2022-10-13 19:31:56 UTC]    0B base_000000010000000E0000006E_D_000000010000000E0000006B/\n\n[2022-10-13 19:31:56 UTC] \u00a0\u00a0\u00a0\u00a00B base_000000010000001000000046_D_000000010000000E0000006E/\n</code></pre>"},{"location":"tools/minio/#tips-tricks","title":"Tips &amp; tricks","text":"<p>When files are deleted, they are temporarily stored in a temporary folder for a certain period of time.</p> <p>This temporary folder is cleaned up every 24 hours, removing all data that is 24 hours or older.</p> <p>In theory, temporary data can therefore be cleaned up 47 hours later (if delays occur).</p> <p>While the storage behind MinIO is typically sized sufficiently, if you need to free up space (e.g., by cleaning old backups), you can manually clean temporary data by restarting the MinIO service:</p> <pre><code>[me@acme-dvppg1bc-server1 ~]$ sudo systemctl restart minio.service\n</code></pre> <p>This only affects a backup and restore (they need to be restarted).</p> <p>Recovery (wal-fetch) and archiving (wal-push) are simply replayed and are not impacted by a MinIO restart.</p>"},{"location":"tools/nagios/","title":"Nagios","text":"<p>For the standard PostgreSQL building block, monitoring has been implemented using Nagios.</p> <p>This documentation describes how it has been implemented, as well as things that can be better.</p>"},{"location":"tools/nagios/#requirements-and-dependencies","title":"Requirements and Dependencies","text":"<ul> <li>check_postgres</li> <li>ansible-postgres role for nagios</li> <li> <p>nagios server (ansible managed with role):</p> </li> <li> <p><code>gurus-nagios-server1.int.corp.com:/opt/nagios/etc/host.cfg.d/{dbserver fqdn}.cfg</code></p> </li> <li> <p><code>gurus-nagios-server1.int.corp.com:/opt/nagios/etc/host.cfg.d/{dbserver fqdn}-custom.cfg</code></p> </li> <li> <p>db servers (ansible managed with role):</p> </li> <li><code>/etc/nrpe.d/check_certs.cfg</code></li> <li><code>/etc/nrpe.d/check_postgres.cfg</code></li> <li><code>/etc/nrpe.d/multi_check.cfg</code></li> <li><code>/etc/nrpe.d/proces_check.cfg</code></li> <li><code>/etc/nrpe.d/service_check.cfg</code></li> <li><code>/opt/gurus/nrpe/pg_multi_db_checks.sh</code></li> <li><code>/opt/gurus/nrpe/check_postgres_*</code></li> <li><code>/opt/gurus/nrpe/check_certs.sh</code></li> </ul>"},{"location":"tools/nagios/#additional-information","title":"Additional information","text":"<p>The configuration is managed in the Ansible inventory at <code>environments/[ENV]/group_vars/hacluster/nagios.yml</code>: <code>nagios_checks</code></p> <p>For the POC environment, the configuration on Nagios itself is disabled:</p> <pre><code># File: environments/poc/group_vars/hacluster/nagios.yml\nnagios_servers[1].enabled: false\n</code></pre>"},{"location":"tools/nagios/#todo","title":"Todo","text":"<p>The following things can be better:</p> <ul> <li>Nagios monitoring on certificates</li> <li>Currently all regularly monitored for <code>~postgres/.postgresql/postgresql.crt</code></li> <li>Requires a sudo rule for the nrpe user</li> <li>Redesign of the solution would be immensely helpful</li> <li>https://github.com/Vonng/pg_exporter</li> <li>Another solution</li> <li>Newer and likely better than check_postgres</li> <li>Requires some scripting (but much simpler from the check_postgres pl script)</li> <li>Monitoring on wal-g</li> <li>Custom to build</li> <li>How do we get the retention?</li> </ul> <p>2-12-2022: A manual action for now, to ensure the proper functioning of the certificate check:</p> <p>Add the file <code>10_sudo_rule_nrpe_postgres</code> to <code>/etc/sudoers.d/</code> with the following content:</p> <pre><code>nrpe ALL=(postgres) NOPASSWD: ALL\n</code></pre>"},{"location":"tools/pgquartz/","title":"PgQuartz","text":"<p>PgQuartz is a community tool used to configure and execute scheduled jobs in PostgreSQL environments.</p> <p>It reads and runs job configurations defined in YAML files.</p> <p>A job definition can include:</p> <pre><code># Example structure\n\nsteps: # What actions need to be performed\nchecks: # How to verify that everything is working correctly\nconnections: # Definitions of connections to the PostgreSQL environment\netcd_config: # pgquartz can wait for the same job on other servers via etcd\ngeneral_config: # General settings (debug mode, log file path, parallel execution, etc.)\n</code></pre>"},{"location":"tools/pgquartz/#requirements-and-dependencies","title":"Requirements and Dependencies","text":"<p>PgQuartz is installed by default with the PostgreSQL SBB, but it is only used for vaccination certificates.</p> <p>More information:</p> <ul> <li>Inventory</li> <li>PgQuartz</li> </ul>"},{"location":"tools/pgroute66/","title":"PgRoute66","text":"<p>The PostgreSQL building block can optionally be executed with a PostgreSQL router.</p> <p>The router consists of a HA setup with 2 servers, each having a Virtual IP address and running HAProxy and PgRoute66 on both nodes.</p> <p>HAProxy is used to route TCP traffic to the correct PostgreSQL server(s), and PgRoute66 is used to control HAProxy. HAProxy.</p> <p>Pgroute66 is an open-source project and is maintained by the community.</p> <ul> <li>rpmbuilder Releases on GitHub</li> <li>pgvillage Repository</li> </ul>"},{"location":"tools/pgroute66/#requirements","title":"Requirements","text":"<p>For the PostgreSQL router setup, the following components are required for PgRoute66 to function correctly:</p> <ul> <li>The binary is deployed via the depgroute66 RPM (from Satellite).</li> <li>The PgRoute66 configuration file is located at: <code>/etc/pgroute66/config.yaml</code>   and is deployed and managed through Ansible.</li> <li>The PgRoute66 service file can be found at: <code>/etc/systemd/system/pgroute66.service</code>   and is also deployed and managed through Ansible.</li> <li>PgRoute66 runs under the pgroute66 Linux user, which is deployed and managed through Ansible.</li> <li>PgRoute66 uses mTLS for PostgreSQL connections through:</li> <li>a client certificate and key (deployed and managed through Ansible)</li> <li>a root certificate to verify the server certificate (deployed and managed through Ansible)</li> <li>all three located in <code>~pgroute66/.postgresql/</code></li> </ul>"},{"location":"tools/pgroute66/#use","title":"Use","text":"<p>PgRoute66 runs as a service and does not require any manual actions.</p> <p>For troubleshooting, check the service logs:</p> <pre><code>[me@pgv-dvppg1pr-server2 ~] $ sudo journalctl -efu pgroute66.service\n\n-- Logs begin at Thu 2022-10-13 02:09:58 CEST.\nOct 13 22:29:19 pgv-dvppg1pr-server2 pgroute66[1608249]: [GIN] 2022/10/13 - 22:29:19 | 200 | 1.780668ms | 127.0.0.1 | GET \"/v1/standbys\"\nOct 13 22:29:19 pgv-dvppg1pr-server2 pgroute66[1608249]: [GIN] 2022/10/13 - 22:29:19 | 200 | 1.951384ms | 127.0.0.1 | GET \"/v1/primary\"\nOct 13 22:29:21 pgv-dvppg1pr-server2 pgroute66[1608249]: [GIN] 2022/10/13 - 22:29:21 | 200 | 1.812061ms | 127.0.0.1 | GET \"/v1/primary\"\nOct 13 22:29:19 pgv-dvppg1pr-server2 pgroute66[1608249]: [GIN] 2022/10/13 - 22:29:19 | 200 | 1.986874ms | 127.0.0.1 | GET \"/v1/standbys\"\nOct 13 22:29:20 pgv-dvppg1pr-server2 pgroute66[1608249]: [GIN]2022/10/13 - 22:29:20 | 200 | 1.917752ms | \u00a0 127.0.0.1 | GET \"/v1/standbys\"\nOct 13 22:29:20 pgv-dvppg1pr-server2 pgroute66[1608249]: [GIN]2022/10/13 - 22:29:20 | 200 | 1.69516ms |     127.0.0.1 | GET \"/v1/primary\"\nOct 13 22:29:21 pgv-dvppg1pr-server2 pgroute66[1608249]: [GIN]2022/10/13 - 22:29:21 | 200 | 1.957809ms |   127.0.0.1 | GET \"/v1/standbys\"\nOct 13 22:29:21 pgv-dvppg1pr-server2 pgroute66[1608249]: [GIN]2022/10/13 - 22:29:21 | 200 | 1.812061ms | \u00a0 127.0.0.1 | GET\u00a0 \"/v1/primary\"\nOct 13 22:29:21 pgv-dvppg1pr-server2 pgroute66[1608249]: [GIN]2022/10/13 - 22:29:21 | 200 | 1.606772ms |  127.0.0.1 | GET \"/v1/standbys\"\n</code></pre> <p>If necessary, the logging can also be temporarily increased by raising the log level to debug in the config file:</p> <pre><code>[me@pgv-dvppg1pr-server2 ~]$ vim /etc/pgroute66/config.yaml\n\n[me@pgv-dvppg1pr-server2 ~]$ grep loglevel /etc/pgroute66/config.yaml\n\nloglevel: develop\n\n[me@pgv-dvppg1pr-server2 ~]$ systemctl restart pgroute66.service\n</code></pre> <p>Note</p> <p>HAProxy and PgRoute66 are loosely coupled, and a successful restart of the pgroute66 has no impact on the availability of the service.</p>"},{"location":"tools/pgroute66/#todo","title":"ToDo","text":"<p>PgRoute66 could be enhanced to detect the primary database based on Stolon configuration in etcd.</p> <p>In that case, PgRoute66 can run on the database server along with it and HAProxy can be used without the <code>external-check</code> and <code>insecure-fork-wanted</code> options.</p>"},{"location":"tools/stolon/","title":"Stolon","text":"<p>Stolon is a PostgreSQL High Availability (HA) tool that uses etcd (or another key/value store) for consensus.</p> <p>This means etcd ensures the entire cluster shares the same configuration, and Stolon uses that configuration to create and manage an HA PostgreSQL cluster.</p> <p>Stolon provides, among other things:</p> <ul> <li>One-time initialization of the cluster</li> <li>Cloning the master to the standbys</li> <li>Management of replication</li> <li>Management of High Availability</li> <li>Routing 25432 to 5432 on the master\u00a0(stolon-proxy)</li> <li>Configuration management (pg_hba.conf and postgresql.conf)</li> </ul> <p>Stolon is an open-source project maintained by the community.</p> <ul> <li>rpmbuilder Releases on GitHub</li> <li>pgvillage Repository</li> </ul> <p>Intent: The goal is to get these two pull requests merged upstream so separate builds are no longer required.</p>"},{"location":"tools/stolon/#requirements","title":"Requirements","text":"<p>For a stolon, the following components are needed:</p> <ul> <li> <p>Stolon binaries   Installed in <code>/usr/local/bin/</code> via the RPM:</p> </li> <li> <p><code>stolonctl</code> \u2013 CLI management tool</p> </li> <li><code>stolon-keeper</code> \u2013 PostgreSQL manager</li> <li><code>stolon-proxy</code> \u2013 TCP proxy for forwarding traffic to the master</li> <li> <p><code>stolon-sentinel</code> \u2013 Cluster manager</p> </li> <li> <p>Systemd files   Deployed by Ansible to <code>/etc/systemd/system/</code>:</p> </li> <li> <p><code>stolon-keeper.service</code></p> </li> <li><code>stolon-proxy.service</code></li> <li> <p><code>stolon-sentinel.service</code></p> </li> <li> <p>The stolon config files   Deployed by Ansible to <code>/etc/sysconfig/</code>:</p> </li> <li> <p><code>stolon-stkeeper</code></p> </li> <li><code>stolon-stproxy</code></li> <li> <p><code>stolon-stsentinel</code></p> </li> <li> <p>a working etcd and configuration to access it</p> </li> <li>We use the standard ports, but if not, then the custom port must be configured</li> <li>We don't yet use etcd with tls / client certificate, but if so, then the certificates need to be available and configured</li> <li>stolon takes care of all postgres matters, including initialization, cloning, and starting Postgres</li> <li>stolon needs the paths to the correct postgres binaries, datadir, and waldir</li> <li>is located in\u00a0<code>/etc/sysconfig/stolon-stkeeper</code></li> </ul>"},{"location":"tools/stolon/#usage","title":"Usage","text":"<p>Configuration and management of Stolon are fully implemented in PgVillage.</p> <p>Furthermore, it is important to be able to use <code>stolonctl</code> in particular to query information and (if necessary) make adjustments.</p> <p><code>stolonctl</code> requires a few configuration parameters so that it knows how to connect to etcd and which cluster it operates on (we use only one, but the configuration is still necessary).</p> <p>With these parameters set, stolonctl can be used under any user (connect to etcd via the API).</p> <p>A few examples:</p>"},{"location":"tools/stolon/#check-status","title":"Check Status","text":""},{"location":"tools/stolon/#setting-up-environment-variables","title":"Setting up Environment Variables","text":"<pre><code>export STOLONCTL_CLUSTER_NAME=stolon-cluster\nexport STOLON_CTL_STORE_BACKEND=etcdv3\n</code></pre>"},{"location":"tools/stolon/#check-cluster-status","title":"Check Cluster Status","text":"<pre><code>[root@acme-dvppg1db-server1 sysconfig]#/usr/local/bin/stolonctl status\n</code></pre> <p>=== Active Sentinels === ID LEADER 3b05c06e true 6b467314 false 7ae581ff false 902f6b4d false</p> <p>=== Active Proxies === ID 09605cac 308fcad1 4a1634ea 534074d4</p> <p>=== Keepers ===</p> <p>UID HEALTHY PG_LISTEN_ADDRESS PG_HEALTHY PG_WANTED_GEN PG_CURRENT_GEN acme_dvppg1db_server1 true 10.0.4.42:5432 true 33 33 acme_dvppg1db_server2 true 10.0.4.43:5432 true 55 55 acme_dvppg1db_server3 true 10.0.4.44:5432 true 33 33 acme_dvppg1db_server4 true 10.0.4.45:5432 true 33 33</p> <p>===Cluster Info=== MasterKeeper: acme_dvppg1db_server2</p> <p>== Keepers/DB Tree == acme_dvppg1db_server2 (master) \u251c\u2500 acme_dvppg1db_server4 \u251c\u2500 acme_dvppg1db_server3 \u2514\u2500 acme_dvppg1db_server1</p>"},{"location":"tools/stolon/#query-the-current-configuration","title":"Query the current configuration","text":"<pre><code>#set up config required for stolonctl\n\nexport STOLONCTL_CLUSTER_NAME=stolen-cluster\n\nexport STOLONCTL_STORE_BACKEND=etcdv3\n\n# Request cluster spec\n\n[root@acme-dvppg1db-server1 sysconfig]# /usr/local/bin/stolonctl spec\n\nOutcome:\n\n{\n\n\"initMode\": \"new\",\n\"defaultSUReplAccessMode\": \"strict\",\n\"pgParameters\": {\n\"archive_command\": \"/opt/wal-g/scripts/archive.sh %p\",\n\"archive_mode\": \"on\",\n\"datestyle\": \"ISO, MDY\",\n\"default_text_search_config\": \"pg_catalog.english\",\n\"dynamic_shared_memory_type\": \"posix\",\n\"effective_cache_size\": \"5822MB\",\n\"idle_in_transaction_session_timeout\": \"60 minutes\",\n\"lc\\_messages\": \"en\\_US.UTF-8\",\n\"LC_MONETARY\": \"en_US.UTF-8\"\n\"lc_numeric\": \"C.UTF-8\",\n\"lc_time\": \"en_US.UTF-8\",\n\"listen_addresses\": \"['*']\",\n\"log_connections\": \"on\",\n\"log_destination\": \"csvlog\",\n\"log_directory\": \"/var/log/postgresql\",\n\"log_disconnections\": \"on\",\n\"log_error_verbosity\": \"verbose\",\n\"log_file_mode\": \"0600\",\n\"log_filename\": \"postgresql-%Y%m%d.log\",\n\"log_line_prefix\": \"%m [%p%: [%l-1] db=%d,user=%u,app=%a,client=%h \",\n\"log_min_duration_statement\": \"5000\",\n\"log_min_error_statement\": \"error\",\n\"log_min_messages\": \"warning\",\n\"log_rotation_age\": \"1d\",\n\"log_rotation_size\": \"1GB\",\n\"log_statement\": \"ddl\",\n\"log_timezone\": \"Europe/Amsterdam\",\n\"log_truncate_on_rotation\": \"on\",\n\"logging_collector\": \"on\",\n\"max_connections\": \"100\",\n\"max_parallel_workers\": \"8\",\n\"max_parallel_workers_per_gather\": \"2\",\n\"max_wal_senders\": \"3\",\n\"max_wal_size\": \"76762MB\",\n\"max_worker_processes\": \"8\",\n\"min_wal_size\": \"25587MB\",\n\"restore_command\": \"/opt/wal-g/scripts/archive_restore.sh %f %p\",\n\"shared_buffers\": \"1940MB\",\n\"ssl\": \"true\",\n\"ssl_ca_file\": \"/data/postgres/data/certs/root.crt\",\n\"ssl_cert_file\": \"/data/postgres/data/certs/server.crt\",\n\"ssl_key_file\": \"/data/postgres/data/certs/server.key\",\n\"statement_timeout\": \"60min\",\n\"timezone\": \"Europe/Amsterdam\",\n\"wal_level\": \"archive\",\n\"work_mem\": \"29813kB\"\n\n},\n\n\"pgHBA\": [\n\n[local] all all ident\n\n\"hostssl postgres avchecker samenet cert\",\n\nhostssl vcbe_db cims_rw sanet scram-sha-256,\n\n\"hostssl all all samenet cert\"\n\n\\]\n</code></pre>"},{"location":"tools/stolon/#update-cluster-config","title":"Update cluster config","text":"<pre><code>set up configuration required for stolonctl\n\nexport STOLONCTL_CLUSTER_NAME=stolon-cluster\n\nexport STOLONCTL_STORE_BACKEND=etcdv3\n\n# adjust cluster spec\n\n/usr/local/bin/stolonctl update -f /data/postgres/data/stolon\\_custom\\_config.yml --patch\n\nThe command should give no output (if it works correctly).\n\n# Patch\n\nIncidentally, the patch offers options to adjust configurations, but this configuration \"comes alongside.\"\n\nSettings that do not receive a value from the custom_config file retain their current configuration.\n\nThe entire configuration can also be completely adjusted by first setting it with the `spec` option in a file, then making adjustments, and finally reloading without the `--patch` option using `stolonctl update`.\n\nset up configuration required for stolonctl\n\nexport STOLONCTL_CLUSTER_NAME=stolon-cluster\n\nexport STOLONCTL_STORE_BACKEND=etcdv3\n\n\n# dumping\n/usr/local/bin/stolonctl spec &gt; /tmp/stolon_custom_config.yml\n\n# adjust\nedit /tmp/stolon_custom_config.yml\n\n\n# Check if it's still JSON.\ncat /tmp/stolon\\_custom\\_config.yml \\| python -m json.tool\n\n#read cluster specification\n/usr/local/bin/stolonctl update -f /data/postgres/data/stolon_custom_config.yml\n</code></pre>"},{"location":"tools/stolon/#help","title":"Help","text":"<p>To list all options of <code>stolonctl</code>, you can run the command with the <code>-h</code> option:</p> <pre><code>stolonctl -h\nOr use the `--help` option:\nstolonctl --help\n\n[root@acme-dvppg1db-server1 sysconfig]# /usr/local/bin/stolonctl\n\nstolon command line client\n\nUsage:\n\nstolonctl [Flags]\nstolonctl [command]\n</code></pre> <p>Available Commands: manage cluster data Manage current cluster data</p> <p>Failkeeper - Force keeper as \"temporarily\" failed. The sentinel will compute new cluster data, considering it as failed, and then restore its state to the actual one.</p> <p>help \u00a0\u00a0Help about any command</p> <pre><code>| Command | Description |\n|----------|-------------|\n| `initialize` | Initialize a new cluster |\n| `promote` | Promote a standby to primary |\n| `register`\u00a0|\u00a0Register stolon keepers for service discovery |\n| `removekeeper` | Removes keeper from cluster data |\n| `spec` | Retrieve current cluster specification |\n| `status` | Display the current cluster status |\n| `update` | Update cluster configuration |\n| `version` | Show stolonctl version |\n\n# Flags:\n\n--cluster-name string            cluster name\n-h, --help                       help for stolonctl\n--kube-context string             name of the kubeconfig context to use\n--kube-namespace string           name of the Kubernetes namespace to use\n\n--kube-resource-kind string       the Kubernetes resource kind to be used to store Stolon cluster data\n                                  and perform sentinel leader election (currently, only \"configmap\" is supported).\n\n--kubeconfig string               path to kubeconfig file. Overrides $KUBECONFIG\n--log-level string                debug, info (default), warn or error (default \"info\")\n--metrics-listen-address string   metrics listen address, e.g., \"0.0.0.0:8080\" (disabled by default)\n--store-backend string            store backend type (etcdv2/etcd, etcdv3, consul, or kubernetes)\n--store-ca-file string            verify certificates of HTTPS-enabled store servers using this CA bundle\n--store-cert-file string          certificate file for client identification to the store\n--store-endpoints string          a comma-delimited list of store endpoints\n                                  (use https scheme for TLS communication)\n                                  (defaults: http://127.0.0.1:2379 for etcd, http://127.0.0.1:8500 for consul)\n--store-key string                private key file for client identification to the store\n--store-prefix string             the store base prefix (default \"stolon/cluster\")\n--store-skip-tls-verify           skip store certificate verification (insecure!!!)\n--store-timeout duration          store request timeout (default 5s)\n--version                         version for stolonctl\n</code></pre> <p>Use <code>stolonctl [command] --help</code> for more information about a specific command.</p>"},{"location":"tools/stolon/#when-nothing-else-works","title":"When Nothing Else Works","text":"<p>In some cases, Stolon may fail to recover automatically.</p> <p>The situation was as follows:</p> <ul> <li>The 3rd node was (according to Stolon) the master.</li> <li>The 3rd node had issues with the datadir and refused to start again.</li> <li>The other nodes were also not okay anymore.</li> </ul> <p>This has been resolved by reinitializing the cluster:</p> <pre><code># Set up configuration required for `stolonctl`.\n\nexport STOLONCTL_CLUSTER_NAME=stolon-cluster\nexport STOLONCTL_STORE_BACKEND=etcdv3\n\n# reinitialize\n/usr/local/bin/stolonctl init\n</code></pre> <p>Note</p> <p>Preferably perform a point-in-time restore!!!</p> <p>There is a \"are you sure\" prompt and then the cluster information is cleared afterwards.</p> <p>Once confirmed, the existing cluster metadata will be cleared.</p> <p>After that, the backup was discarded and restored.</p> <p>This approach is not recommended for production use.</p> <p>It is better to use the Point in time restore procedure. It also executes an init but with the PITR option so that the latest backup is restored from WAL-G.</p>"},{"location":"tools/wal-g/","title":"WAL-G","text":"<p>For backup and restore, we use Wal-G and MinIO.</p> <p>WAL-G is an open-source project maintained by the community.</p> <ul> <li>rpmbuilder Releases on GitHub</li> <li>pgvillage Repository</li> </ul> <p>At the time of this writing, an adapted RPM is being used, which is based on:</p> <ul> <li>The latest version of https://github.com/wal-g/wal-g/tags</li> <li>This change: https://github.com/wal-g/wal-g/pull/1269 (for restoring delta backups of Stolon managed databases)</li> </ul> <p>The intention is to get this pull request merged so that separate builds are no longer needed.</p>"},{"location":"tools/wal-g/#requirements","title":"Requirements","text":"<p>For making wal-g, the following components are needed:</p>"},{"location":"tools/wal-g/#1-wal-g-binary","title":"1. WAL-G Binary","text":"<ul> <li>Installed via RPM to <code>/usr/local/bin/</code></li> </ul>"},{"location":"tools/wal-g/#2-scripts","title":"2. Scripts","text":"<p>Deployed by Ansible to <code>/opt/wal-g/scripts/</code>:</p> <ul> <li><code>archive_restore.sh</code> \u2013 used for catch-up when a standby lags behind or during recovery</li> <li><code>archive.sh</code> \u2013 sends WAL files to MinIO using WAL-G</li> <li><code>backup_locked.sh</code> \u2013 wrapper script using <code>etcdctl lock</code> to ensure backups run on only one server</li> <li><code>backup.sh</code> \u2013 creates a new backup if there isn\u2019t a recent one</li> <li><code>delete.sh</code> \u2013 cleans up old backups</li> <li><code>log_cleanup.sh</code> \u2013 maintains WAL-G log files</li> <li><code>maintenance.sh</code> \u2013 wrapper for <code>log_cleanup.sh</code> and <code>delete.sh</code></li> <li><code>restore.sh</code> \u2013 restores a WAL-G backup (see Point in time restore for more information)</li> </ul>"},{"location":"tools/wal-g/#3-cron-scheduling","title":"3. Cron Scheduling","text":"<ul> <li>Managed by Ansible</li> <li>Cron file: <code>/etc/cron.d/wal-g</code></li> </ul>"},{"location":"tools/wal-g/#4-configuration-file","title":"4. Configuration File","text":"<ul> <li>File: <code>/etc/default/wal-g</code> (maintained by Ansible)</li> <li>Contains:</li> <li>Retention policies</li> <li>Number of delta backups</li> <li>Backup skip intervals</li> </ul>"},{"location":"tools/wal-g/#5-minio-configuration","title":"5. MinIO Configuration","text":"<ul> <li>MinIO runs on the backup server</li> <li>Access configuration is included in <code>/etc/default/wal-g</code></li> <li>Root certificate located in <code>~postgres/.wal-g/certs/</code> (for TLS verification)</li> </ul>"},{"location":"tools/wal-g/#use","title":"Use","text":"<p>Essentially, everything is automated using Ansible, Bash scripts, and cron.</p> <p>You can even perform a Point-in-Time Restore using this procedure: Point in time restore.</p> <p>However, if desired, wal-g can also be invoked as a command-line tool.</p> <p>That works as follows:</p>"},{"location":"tools/wal-g/#configuring-wal-g-for-use","title":"Configuring WAL-G for Use","text":"<p>We do this by sourcing the environment variables using the following command:</p> <p>Read the configuration from <code>/etc/default/wal-g</code></p> <pre><code># Skip lines with a #\n# Export them as variables for subcommands\neval \"$(sed '/#/d;s/^/export /' /etc/default/wal-g)\"\n</code></pre> <p>Then wal-g can be called directly.</p> <p>A few examples:</p> <p>Checking which backups are available</p> <pre><code>[postgres@acme-dvppg1db-server2 ~] $ /usr/local/bin/wal-g-pg backup-list\n...\nname                                                       modified             wal_segment_backup_start\nbase_000000010000000C0000000E                              2022-10-11T14:54:12Z 000000010000000C0000000E\nbase_000000010000000E00000069_D_000000010000000C0000000E   2022-10-12T07:08:48Z 000000010000000E00000069\nbase_000000010000000E0000006B                              2022-10-12T07:29:37Z 000000010000000E0000006B\nbase_000000010000000E0000006N_D_000000010000000E0000006B   2022-10-12T18:02:06Z 000000010000000E0000006N\nbase_000000010000001000000046_D_000000010000000E0000006E   2022-10-13T18:02:17Z 000000010000001000000046\n</code></pre>"},{"location":"tools/wal-g/#backups-can-be-deleted","title":"Backups can be deleted.","text":"<p>For example, you can delete all backups, or (as in the example above) the backups up to <code>base_000000010000000E0000006B</code>:</p>"},{"location":"tools/wal-g/#remove-all-backups-only-report","title":"Remove all backups (only report)","text":"<p>/usr/local/bin/wal-g-pg delete everything</p> <p>Delete all backups up to base_000000010000000E0000006B (only report)</p> <p>/usr/local/bin/wal-g-pg delete before <code>base_000000010000000E0000006B</code></p> <p>Without the <code>--confirm</code> option, WAL-G only provides a report. With <code>--confirm</code>, it actually performs the deletion.</p>"},{"location":"tools/wal-g/#delete-all-backups-report-and-actually-remove","title":"Delete all backups (report and actually remove)","text":"<p>/usr/local/bin/wal-g-pg delete everything --confirm</p> <p>Delete all backups up to base_000000010000000E0000006B (report and actually remove)</p> <p>/delete wal-g-pg postgres delete before base_000000010000000E0000006B --confirm</p>"},{"location":"tools/wal-g/#help","title":"Help","text":"<p>You can view available commands using:</p> <pre><code>[postgres@acme-dvppg1db-server2 ~]$ /usr/local/bin/wal-g-pg\nPostgreSQL backup tool\n\nUsage:\n\nwal-g [command]\n\nAvailable Commands:\n\nbackup-fetch    Fetch a backup from storage\nbackup-list List available backups\nbackup-mark Mark a backup as permanent or impermanent\nbackup-push Create a backup and upload it to storage\n\n# catchup-fetch\n\nFetches an incremental backup from storage\n\n# Catch-up List\n\nPrints available incremental backups.\ncatchup-push: Creates an incremental backup from LSN\nCompletion: Generate shell completion code for the specified shell.\nduplicate: Duplicate specific or all backups\nDelete: Clears old backups and WALs\n\n# flags\nDisplay the list of available global flags for all wal-g commands\nhelp Help about any command\n\npgbackrest\nInteract with pgBackRest backups (beta)\nst (DANGEROUS) Storage tools\n\nwal-fetch Fetches a WAL file from storage\nwal-push    Uploads a WAL file to storage\nwal-receive \u00a0\u00a0Receive WAL stream with postgres Streaming Replication Protocol and push to storage\nwal-restore \u00a0\u00a0Restores WAL segments from storage.\nwal-show     Show information about storage WAL segments, grouped by timelines.\nwal-verify Verify WAL storage folder. Available checks: integrity, timeline.\n\n# Flags:\n--config string   config file (default is $HOME/.walg.json)\n-h, --help          help for wal-g\n--turbo        Ignore all kinds of throttling defined in config\n- `-v`, `--version`\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 version voor `wal-g`\n\nTo obtain a complete list of all global flags, execute: `wal-g flags`\n\nUse `wal-g [command] --help` for more information about a command.\n\n### Help for the `delete` Command\n\n[postgres@acme-dvppg1db-server2 ~]$ /usr/local/bin/wal-g-pg delete --help\nClears old backups and WALs\n\nUsage:\nwal-g delete [command]\n\nAvailable Commands:\nbefore\neverything\ngarbage\nretain\ntarget\n\nFlags:\n--confirm \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Confirms backup deletion\n-h, --help  help for delete\n--use-sentinel-time Use backup creation time from sentinel for backups ordering.\n\nGlobal Flags:\n--config string    config file (default is $HOME/.walg.json)\n--turbo     Ignore all kinds of throttling defined in config\n</code></pre> <p>To get the complete list of all global flags, run: <code>wal-g flags</code></p> <p>Use \"wal-g delete [command] --help\"for more information about a command.</p>"},{"location":"users-guide/client_connection_failover/","title":"Client connection failover","text":""},{"location":"users-guide/client_connection_failover/#belongs-to-component","title":"Belongs to Component","text":"<p>Postgres</p>"},{"location":"users-guide/client_connection_failover/#introduction","title":"# Introduction","text":"<p>In the Postgres environment, clusters are provided that consist of 3 or more database clusters and a backup server. In some environments, currently the two DVP clusters and the POC environment, there are also two proxy servers with a VIP address.</p> <p>In environments with a VIP address, accessing the database is straightforward. By using the VIP, you always connect to the primary database.</p> <p>In environments without VIP and proxy servers, there are usually three database servers where it is not known which one is the primary; this can also change, for example, during patching. To connect to the primary database, there are a few options. <pre><code>## Requirements and dependencies\n\nThe database(s) can be accessed in various ways, each with its own specifics; we describe the following:\n\n- psql on Linux  \n- PGAdmin on Windows  \n- DBeaver on Windows\n\n## Performance\n\nUsing `psql` on Windows allows you to utilize the 'service file' (`.pg_service.conf` in `$HOME`) for configuration, including connection details. Below is an example of how to connect to either a primary or slave server without knowing which one it is. In the 'service file', this can be specified as follows:\n</code></pre> [master] <pre><code>\n</code></pre> host=gurus-pgsdb-server1.int.corp.com, gurus-pgsdb-server2.int.corp.com, gurus-pgsdb-server3.int.corp.com <pre><code>`port=5432`\n\n```markdown\ntarget_session_attrs=read-write\n</code></pre></p> <pre><code>sslmode=verify-full\n</code></pre> <p>[standby]</p> <pre><code>host=gurus-pgsdb-server1.int.corp.com, gurus-pgsdb-server2.int.corp.com, gurus-pgsdb-server3.int.corp.com\n</code></pre> <p>port=5432</p> <p><code>target_session_attrs=read-only</code></p> <p>This way, the connection can be made with <code>service=master</code> to the primary database and with <code>server=standby</code> to any standby database:</p>"},{"location":"users-guide/client_connection_failover/#psql-op-linux","title":"psql op Linux","text":"<p>The situation:</p> <pre><code>gurus_pgsdb_server1 (master)\n</code></pre> <p>\u251c\u2500gurus_pgsdb_server2</p>"},{"location":"users-guide/client_connection_failover/#gurus_pgsdb_server3","title":"gurus_pgsdb_server3","text":"<p>$ hostname --fqdn</p> <p><code>scc-pgsdb-server2.int.corp.com</code></p> <pre><code>$ **psql service=master**\n</code></pre> <p>psql (14.5)</p> <pre><code>SSL connection (protocol: TLSv1.3, cipher: TLS_AES_256_GCM_SHA384, bits: 256, compression: off)\n</code></pre> <p>Type \"help\" for help.</p> <pre><code>postgres=# select pg_is_in_recovery();\n</code></pre> <pre><code>pg_is_in_recovery\n</code></pre> <p>-------------------</p> <p>f</p> <p>(1 row)</p> <pre><code>postgres=# exit;\n</code></pre> <pre><code>Database is not recovering and is therefore the primary!\n</code></pre> <pre><code>$ **psql service=primary**\n</code></pre> <p>psql (14.5)</p> <p>SSL connection (protocol: TLSv1.3, cipher: TLS_AES_256_GCM_SHA384, bits: 256, compression: off)</p> <p>Enter \"help\" for assistance.</p> <p>The indication of standby and master comes from the 'service file' and can be filled or expanded according to your own understanding.</p> <pre><code>SELECT pg_is_in_recovery();\n</code></pre> <pre><code>`pg_is_in_recovery`\n</code></pre> <p>-------------------</p> <p>t</p> <p>(1 row)</p> <pre><code>postgres=# exit;\n</code></pre> <p>Now we see that the database is in <code>recovery_mode</code>, which means it's a standby/slave database.</p>"},{"location":"users-guide/client_connection_failover/#pgadmin-for-windows","title":"PGAdmin for Windows","text":"<p>For PGAdmin, it also applies that this can make use of the aforementioned 'service file'; it works identically to what has been described above. If PGAdmin is used on Windows, then the peculiarity is the name and location of the 'service file', namely:</p> <p>\\%APPDATA%\\postgresql.pg_service.conf (where\u00a0\\%APPDATA\\% refers to the Application Data subdirectory in the user's profile), where on Linux this file is: ~/.pg_service.conf</p> <p>In de windows van PGAdmin kan dit verder eenvoudig worden ingevuld.</p> <p>The 'service file' contains the following:</p> <p><code>[aermaster]</code></p> <p><code>port=5432</code></p> <pre><code>target_session_attrs=read-write\n</code></pre> <p>So if we make the connection this way, it ends up on the master!</p> <p></p>"},{"location":"users-guide/client_connection_failover/#dbeaver","title":"Dbeaver","text":"<p>For DBeaver on Windows, it works a bit differently; here, the JDBC URL is used, which needs to be entered in the DBeaver window, somewhat depending on the version.</p> <p>An example is: <code>jdbc:postgresql://node1,node2,node3/accounting?targetServerType=primary</code></p> <p>Hiermee wordt weer bereikt dat de connectie wordt gemaakt naar de master database waar read/write acties mogelijk zijn.</p> <pre><code>![1672242748155-292.png](../../../../../../../../../attachment/xwiki/Infrastructuur/Team%3A%20DBA/Algemene%20Restore%20Server%20voor%20DBA-Linux/Postgres/Bouwsteen/Onderhoud/Connect%20to%20primary%20or%20slave/WebHome/1672242748155-292.png)\n</code></pre> <p>NB: Screenprint is a newer version than what's present on the management server; this is version 22.3.0.</p> <p>Als de connect niet ' goed' wordt gemaakt, bv connected aan readonly (slave) omgeving kan de volgende 'foutmelding' worden getoond als er een poging wordt gedaan om iets weg te schrijven:</p> <pre><code>Caused by: liquibase.exception.DatabaseException: ERROR: cannot execute CREATE TABLE in a read-only transaction [Failed SQL: (0)]\n</code></pre> <p>This will then be displayed, an error message, but clearly explainable!</p>"},{"location":"users-guide/clients/","title":"Introduction","text":"<p>Er zijn vele verschillende programeertalen die een verbidning kunnen maken naar PostgreSQL en de meesten hebben een eigen client.</p> <p>Deze documentaie helpt de eindgebruiker op weg om suucesvol een client verbinding op te zetten.</p>"},{"location":"users-guide/clients/#dependencies","title":"Dependencies","text":"<ul> <li>JDBC documentation (Java)</li> <li>https://jdbc.postgresql.org/documentation/use/#connection-parameters/</li> <li> <p>https://jdbc.postgresql.org/documentation/ssl/</p> </li> <li> <p>libpq documentation (Python =&gt; psycopg2, C clients, PostgreSQL tools)</p> </li> <li>https://jdbc.postgresql.org/documentation/ssl/</li> <li> <p>https://www.postgresql.org/docs/current/libpq-connect.html#LIBPQ-PARAMKEYWORDS</p> </li> <li> <p>nPGSQL (.NET)</p> </li> <li> <p>https://www.npgsql.org/doc/</p> </li> <li> <p>Information for the applicant:\u00a0mail to the applicant</p> </li> <li> <p>pg_service.conf information</p> </li> <li>https://www.postgresql.org/docs/current/libpq-pgservice.html</li> <li> <p>pg_service</p> </li> <li> <p>Client certificates:</p> </li> <li>General information</li> <li>Generate new certificates</li> <li>openssl commands to convert and read</li> </ul>"},{"location":"users-guide/clients/#instructions","title":"Instructions","text":"<p>Afhankelijk van de driver dient de configuratie op een andere manier te geschieden.</p> <p>Kijk bij de Afhankelijkheden lijst naar de bestreffende soort driver en lees de bijbehorende documentatie.</p> <p>Furthermore, the following should be taken into account:</p> <ul> <li>Use the latest version of the driver whenever possible</li> <li>At a minimum, use the version that was released after the used PostgreSQL Major. Example:<ul> <li>PostgreSQL 14</li> <li>https://www.postgresql.org/support/versioning/ =&gt; September 30, 2021</li> <li>https://mvnrepository.com/artifact/org.postgresql/postgresql =&gt; at least 42.3.0</li> </ul> </li> <li>The client certificate, private key, and root certificate must be readable by the application user account.</li> <li>Ensure the path is configured correctly. See mail to the requester for options to deliver the information to the end-user.</li> <li>Note: Private keys must only be sent encrypted!!!</li> <li>Direct connection to PostgreSQL (port 5432 of the database hosts)</li> <li>has several advantages<ul> <li>A direct connection avoids (software / network) hops and associated latencies</li> <li>The hba file can be configured more specifically</li> </ul> </li> <li>however, it also has disadvantages<ul> <li>follow the master is 100% dependent on the intelligence of the driver and the software that uses it</li> <li>See the following documentation for Client Connect Failover (follow the master)</li> <li>jdbc: https://jdbc.postgresql.org/documentation/use/#connection-fail-over</li> <li>libpq: https://www.postgresql.org/docs/current/libpq-connect.html#LIBPQ-PARAMKEYWORDS<ul> <li>Check out target_session_attrs</li> <li>Options are version-dependent</li> </ul> </li> </ul> </li> </ul>"},{"location":"users-guide/jdbc/","title":"Introduction","text":"<p>De jdbc client kan geconfigureerd worden met een jdbc url.</p> <p>Deze werkinstructie geeft wat suggesties voor de vorm.</p> <p>The SSL parameters are included (for convenience).</p>"},{"location":"users-guide/jdbc/#dependencies","title":"Dependencies","text":"<pre><code>- [server request](../../../../../../../../../pages/xwiki/Infrastructuur/Team%253A+DBA/Werkinstrukties/Postgres/Bouwsteen/Van+database+aanvraag+naar+server+aanvraag/WebHome.html)\n- [set up cluster](../../../../../../../../../pages/xwiki/Infrastructuur/Team%253A+DBA/Werkinstrukties/Postgres/Bouwsteen/Van+server+naar+draaiende+database/WebHome.html)\n- [client connection information](../../../../../../../../../pages/xwiki/Infrastructuur/Team%253A+DBA/Werkinstrukties/Postgres/Bouwsteen/Clients/WebHome.html)\n- [Client certificates](../../../../../../../../../pages/xwiki/Infrastructuur/Team%253A+DBA/Werkinstrukties/Postgres/Bouwsteen/mTLS/Client+certificaten/WebHome.html)\n</code></pre>"},{"location":"users-guide/jdbc/#instruction","title":"Instruction","text":"<p>Wat voorbeelden vn jdb urls:</p>"},{"location":"users-guide/jdbc/#rw","title":"rw:","text":"<pre><code>postgres://{user}@{db hosts separated by ,}:5432/{database name}?sslmode=verify-full&amp;sslcert=/home/{user}/.postgresql/{user}.crt&amp;sslkey=/home/{user}/.postgresql/{user}.key&amp;sslrootcert=/home/{user}/.postgresql/root.crt\n</code></pre>"},{"location":"users-guide/jdbc/#proxy","title":"proxy:","text":"<p>-</p> <pre><code>postgres://{user}@{db hosts separated by ,}:25432/{database name}?sslmode=verify-full&amp;sslcert=/home/{user}/.postgresql/{user}.crt&amp;sslkey=/home/{user}/.postgresql/{user}.key&amp;sslrootcert=/home/{user}/.postgresql/root.crt\n</code></pre>"},{"location":"users-guide/jdbc/#vip_rw","title":"vip_rw:","text":"<pre><code>postgres://{user}@{vip fqdn}:5432/{database name}?sslmode=verify-full&amp;sslcert=/home/{user}/.postgresql/{user}.crt&amp;sslkey=/home/{user}/.postgresql/{user}.key&amp;sslrootcert=/home/{user}/.postgresql/root.crt\n</code></pre>"},{"location":"users-guide/jdbc/#vip_ro","title":"vip_ro","text":"<pre><code>postgres://{user}@{vip fqdn}:5433/{database name}?sslmode=verify-full&amp;sslcert=/home/{user}/.postgresql/{user}.crt&amp;sslkey=/home/{user}/.postgresql/{user}.key&amp;sslrootcert=/home/{user}/.postgresql/root.crt\n</code></pre> <p>Starting point is that:</p> <ul> <li><code>{user}</code> is replaced by the Postgres user.  </li> <li>This must match the Postgres user.  </li> <li> </li> </ul> <pre><code>openssl x509 -text -noout -in /home/{user}/.postgresql/{user}.crt | sed -n '/Subject:/{s/.\\*= //;p}'\n- {vip fqdn} moet vervangen worden door het IP adres van de VIP\n- {database name} moet vervangen werden door de naam van de Postgres Database\n- {list of all hosts, separated by ,} moet vervangen worden door een lijst van de servers, e.a.\n</code></pre> <pre><code>gurus-pgsdb-server1.int.corp.com, gurus-pgsdb-server2.int.corp.com, gurus-pgsdb-server3.int.corp.com\n- The certificate files are indeed stored in the respective subdirectory.\n</code></pre>"},{"location":"users-guide/jdbc/#this-must-match-the-common-name-of-the-client-certificate","title":"This must match the Common Name of the client certificate:","text":""}]}